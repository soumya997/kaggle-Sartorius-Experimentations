{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Coco Dataset Notebook and Inference Notebook**","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/vexxingbanana/sartorius-coco-dataset-notebook\n\nhttps://www.kaggle.com/vexxingbanana/mmdetection-neuron-inference","metadata":{}},{"cell_type":"markdown","source":"# **References**","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/dschettler8845/sartorius-segmentation-eda-and-baseline\n\nhttps://www.kaggle.com/ihelon/cell-segmentation-run-length-decoding\n\nhttps://www.kaggle.com/stainsby/fast-tested-rle\n\nhttps://www.kaggle.com/paulorzp/run-length-encode-and-decode\n\nhttps://www.kaggle.com/awsaf49/sartorius-mmdetection-infer\n\nhttps://www.kaggle.com/awsaf49/sartorius-mmdetection-train\n\nhttps://www.kaggle.com/evancofsky/sartorius-torch-lightning-mask-r-cnn/notebook","metadata":{}},{"cell_type":"markdown","source":"# Notes","metadata":{}},{"cell_type":"markdown","source":"* Trying out more epochs, added more augmentations, increased batch size to 2, and using validation dataset.\n* Added mixed precision, reduced epochs back to 12, removed CLAHE augmentation.\n* Increased confidence on inference of bboxes to 0.5, removed validation.\n* Trying out more epochs, added back 5% validation, changed normalization to the dataset, changed to 3 classes.","metadata":{}},{"cell_type":"markdown","source":"Please consider upvoting if you find this helpful. :)","metadata":{}},{"cell_type":"markdown","source":"# **Install MMDetection and MMDetection-Compatible Torch**","metadata":{}},{"cell_type":"code","source":"!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torch-1.7.0+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torchvision-0.8.1+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torchaudio-0.7.0-cp37-cp37m-linux_x86_64.whl' --no-deps","metadata":{"execution":{"iopub.status.busy":"2021-12-27T19:56:02.946189Z","iopub.execute_input":"2021-12-27T19:56:02.94686Z","iopub.status.idle":"2021-12-27T19:57:10.443978Z","shell.execute_reply.started":"2021-12-27T19:56:02.94678Z","shell.execute_reply":"2021-12-27T19:57:10.443107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install '/kaggle/input/mmdetectionv2140/addict-2.4.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/yapf-0.31.0-py2.py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/terminal-0.4.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/terminaltables-3.1.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/mmcv_full-1_3_8-cu110-torch1_7_0/mmcv_full-1.3.8-cp37-cp37m-manylinux1_x86_64.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/pycocotools-2.0.2/pycocotools-2.0.2' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/mmpycocotools-12.0.3/mmpycocotools-12.0.3' --no-deps\n\n!rm -rf mmdetection\n\n!cp -r /kaggle/input/mmdetectionv2140/mmdetection-2.14.0 /kaggle/working/\n!mv /kaggle/working/mmdetection-2.14.0 /kaggle/working/mmdetection\n%cd /kaggle/working/mmdetection\n!pip install -e .","metadata":{"execution":{"iopub.status.busy":"2021-12-27T19:57:10.4478Z","iopub.execute_input":"2021-12-27T19:57:10.448014Z","iopub.status.idle":"2021-12-27T19:58:00.777505Z","shell.execute_reply.started":"2021-12-27T19:57:10.44799Z","shell.execute_reply":"2021-12-27T19:58:00.776628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Import Libraries** ","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport sklearn\nimport torchvision\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport PIL\nimport json\nfrom PIL import Image, ImageEnhance\nimport albumentations as A\nimport mmdet\nimport mmcv\nfrom albumentations.pytorch import ToTensorV2\nimport seaborn as sns\nimport glob\nfrom pathlib import Path\nimport pycocotools\nfrom pycocotools import mask\nimport numpy.random\nimport random\nimport cv2\nimport re\nfrom mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector\nfrom mmdet.apis import inference_detector, init_detector, show_result_pyplot, set_random_seed","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-27T20:09:07.025935Z","iopub.execute_input":"2021-12-27T20:09:07.026235Z","iopub.status.idle":"2021-12-27T20:09:27.830465Z","shell.execute_reply.started":"2021-12-27T20:09:07.026178Z","shell.execute_reply":"2021-12-27T20:09:27.829596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd ..","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:27.832155Z","iopub.execute_input":"2021-12-27T20:09:27.832438Z","iopub.status.idle":"2021-12-27T20:09:27.838116Z","shell.execute_reply.started":"2021-12-27T20:09:27.832404Z","shell.execute_reply":"2021-12-27T20:09:27.837451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_WIDTH = 704\nIMG_HEIGHT = 520","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:27.839356Z","iopub.execute_input":"2021-12-27T20:09:27.839974Z","iopub.status.idle":"2021-12-27T20:09:27.848761Z","shell.execute_reply.started":"2021-12-27T20:09:27.839938Z","shell.execute_reply":"2021-12-27T20:09:27.847765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Helper Functions**","metadata":{}},{"cell_type":"code","source":"def rle_decode(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\ndef flatten_l_o_l(nested_list):\n    \"\"\" Flatten a list of lists \"\"\"\n    return [item for sublist in nested_list for item in sublist]\n\n\ndef load_json_to_dict(json_path):\n    \"\"\" tbd \"\"\"\n    with open(json_path) as json_file:\n        data = json.load(json_file)\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:27.850894Z","iopub.execute_input":"2021-12-27T20:09:27.851614Z","iopub.status.idle":"2021-12-27T20:09:27.863512Z","shell.execute_reply.started":"2021-12-27T20:09:27.851575Z","shell.execute_reply":"2021-12-27T20:09:27.862772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img_and_mask(img_path, annotation, width, height):\n    \"\"\" Capture the relevant image array as well as the image mask \"\"\"\n    img_mask = np.zeros((height, width), dtype=np.uint8)\n    for i, annot in enumerate(annotation): \n        img_mask = np.where(rle_decode(annot, (height, width))!=0, i, img_mask)\n    img = cv2.imread(img_path)[..., ::-1]\n    return img[..., 0], img_mask\n\ndef plot_img_and_mask(img, mask, invert_img=True, boost_contrast=True):\n    \"\"\" Function to take an image and the corresponding mask and plot\n    \n    Args:\n        img (np.arr): 1 channel np arr representing the image of cellular structures\n        mask (np.arr): 1 channel np arr representing the instance masks (incrementing by one)\n        invert_img (bool, optional): Whether or not to invert the base image\n        boost_contrast (bool, optional): Whether or not to boost contrast of the base image\n        \n    Returns:\n        None; Plots the two arrays and overlays them to create a merged image\n    \"\"\"\n    plt.figure(figsize=(20,10))\n    \n    plt.subplot(1,3,1)\n    _img = np.tile(np.expand_dims(img, axis=-1), 3)\n    \n    # Flip black-->white ... white-->black\n    if invert_img:\n        _img = _img.max()-_img\n        \n    if boost_contrast:\n        _img = np.asarray(ImageEnhance.Contrast(Image.fromarray(_img)).enhance(16))\n        \n    plt.imshow(_img)\n    plt.axis(False)\n    plt.title(\"Cell Image\", fontweight=\"bold\")\n    \n    plt.subplot(1,3,2)\n    _mask = np.zeros_like(_img)\n    _mask[..., 0] = mask\n    plt.imshow(mask, cmap='rainbow')\n    plt.axis(False)\n    plt.title(\"Instance Segmentation Mask\", fontweight=\"bold\")\n    \n    merged = cv2.addWeighted(_img, 0.75, np.clip(_mask, 0, 1)*255, 0.25, 0.0,)\n    plt.subplot(1,3,3)\n    plt.imshow(merged)\n    plt.axis(False)\n    plt.title(\"Cell Image w/ Instance Segmentation Mask Overlay\", fontweight=\"bold\")\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:27.866676Z","iopub.execute_input":"2021-12-27T20:09:27.86687Z","iopub.status.idle":"2021-12-27T20:09:27.880732Z","shell.execute_reply.started":"2021-12-27T20:09:27.866847Z","shell.execute_reply":"2021-12-27T20:09:27.8799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def polygonFromMask(maskedArr, idx):\n    \n    # adapted from https://github.com/hazirbas/coco-json-converter/blob/master/generate_coco_json.py\n    contours, _ = cv2.findContours(maskedArr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    segmentation = []\n    valid_poly = 0\n    for contour in contours:\n        \n    # Valid polygons have >= 6 coordinates (3 points)\n        if contour.size >= 6:\n            segmentation.append(contour.astype(float).flatten().tolist())\n            valid_poly += 1\n    if valid_poly == 0:\n        raise ValueError(idx)\n    \n    return [segmentation]","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:27.882232Z","iopub.execute_input":"2021-12-27T20:09:27.88243Z","iopub.status.idle":"2021-12-27T20:09:27.891027Z","shell.execute_reply.started":"2021-12-27T20:09:27.882407Z","shell.execute_reply":"2021-12-27T20:09:27.890247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Visualizations**","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/sartorius-cell-instance-segmentation/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:27.893954Z","iopub.execute_input":"2021-12-27T20:09:27.894136Z","iopub.status.idle":"2021-12-27T20:09:28.455096Z","shell.execute_reply.started":"2021-12-27T20:09:27.894114Z","shell.execute_reply":"2021-12-27T20:09:28.45435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:28.456482Z","iopub.execute_input":"2021-12-27T20:09:28.456751Z","iopub.status.idle":"2021-12-27T20:09:28.482279Z","shell.execute_reply.started":"2021-12-27T20:09:28.456705Z","shell.execute_reply":"2021-12-27T20:09:28.481603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lines = []\nfor f in train_df.itertuples():\n    lines.append('../input/sartorius-cell-instance-segmentation/train/' + f[1] + '.png')","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:28.483502Z","iopub.execute_input":"2021-12-27T20:09:28.483919Z","iopub.status.idle":"2021-12-27T20:09:28.638144Z","shell.execute_reply.started":"2021-12-27T20:09:28.48388Z","shell.execute_reply":"2021-12-27T20:09:28.637383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lins = pd.Series(lines, name='img_path')","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:28.641792Z","iopub.execute_input":"2021-12-27T20:09:28.643467Z","iopub.status.idle":"2021-12-27T20:09:28.654996Z","shell.execute_reply.started":"2021-12-27T20:09:28.642316Z","shell.execute_reply":"2021-12-27T20:09:28.654283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.concat([train_df, lins], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:28.656268Z","iopub.execute_input":"2021-12-27T20:09:28.656852Z","iopub.status.idle":"2021-12-27T20:09:28.678425Z","shell.execute_reply.started":"2021-12-27T20:09:28.656818Z","shell.execute_reply":"2021-12-27T20:09:28.677753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp_df = train_df.drop_duplicates(subset=[\"id\", \"img_path\"]).reset_index(drop=True)\ntmp_df[\"annotation\"] = train_df.groupby(\"id\")[\"annotation\"].agg(list).reset_index(drop=True)\ntrain_df = tmp_df.copy()","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:28.679706Z","iopub.execute_input":"2021-12-27T20:09:28.679941Z","iopub.status.idle":"2021-12-27T20:09:28.763954Z","shell.execute_reply.started":"2021-12-27T20:09:28.679908Z","shell.execute_reply":"2021-12-27T20:09:28.763252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:28.765452Z","iopub.execute_input":"2021-12-27T20:09:28.765772Z","iopub.status.idle":"2021-12-27T20:09:28.782408Z","shell.execute_reply.started":"2021-12-27T20:09:28.765733Z","shell.execute_reply":"2021-12-27T20:09:28.78161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_mask(idx):\n    im, mk = get_img_and_mask(**train_df[[\"img_path\", \"annotation\", \"width\", \"height\"]].iloc[idx].to_dict())\n    plot_img_and_mask(im, mk)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:28.784285Z","iopub.execute_input":"2021-12-27T20:09:28.784771Z","iopub.status.idle":"2021-12-27T20:09:28.790007Z","shell.execute_reply.started":"2021-12-27T20:09:28.784732Z","shell.execute_reply":"2021-12-27T20:09:28.789261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_mask(0)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:28.791518Z","iopub.execute_input":"2021-12-27T20:09:28.792008Z","iopub.status.idle":"2021-12-27T20:09:29.731801Z","shell.execute_reply.started":"2021-12-27T20:09:28.791972Z","shell.execute_reply":"2021-12-27T20:09:29.731028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_mask(1)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:29.732934Z","iopub.execute_input":"2021-12-27T20:09:29.733193Z","iopub.status.idle":"2021-12-27T20:09:30.467575Z","shell.execute_reply.started":"2021-12-27T20:09:29.733159Z","shell.execute_reply":"2021-12-27T20:09:30.46691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_mask(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:30.468599Z","iopub.execute_input":"2021-12-27T20:09:30.468972Z","iopub.status.idle":"2021-12-27T20:09:31.051164Z","shell.execute_reply.started":"2021-12-27T20:09:30.468937Z","shell.execute_reply":"2021-12-27T20:09:31.050515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, val_df = train_test_split(train_df, train_size=0.95, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:31.052491Z","iopub.execute_input":"2021-12-27T20:09:31.052852Z","iopub.status.idle":"2021-12-27T20:09:31.060424Z","shell.execute_reply.started":"2021-12-27T20:09:31.052819Z","shell.execute_reply":"2021-12-27T20:09:31.059597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:31.061703Z","iopub.execute_input":"2021-12-27T20:09:31.062035Z","iopub.status.idle":"2021-12-27T20:09:31.06738Z","shell.execute_reply.started":"2021-12-27T20:09:31.061998Z","shell.execute_reply":"2021-12-27T20:09:31.066719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile labels.txt\nshsy5y\ncort\nastro","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:31.068695Z","iopub.execute_input":"2021-12-27T20:09:31.069195Z","iopub.status.idle":"2021-12-27T20:09:31.081825Z","shell.execute_reply.started":"2021-12-27T20:09:31.069163Z","shell.execute_reply":"2021-12-27T20:09:31.080867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Config**","metadata":{}},{"cell_type":"code","source":"from mmcv import Config\n# cfg = Config.fromfile('/kaggle/working/mmdetection/configs/htc/htc_x101_64x4d_fpn_dconv_c3-c5_mstrain_400_1400_16x1_20e_coco.py')\ncfg = Config.fromfile('/kaggle/working/mmdetection/configs/ms_rcnn/ms_rcnn_x101_32x4d_fpn_1x_coco.py')\n# cfg = Config.fromfile('/kaggle/working/mmdetection/configs/cascade_rcnn/cascade_mask_rcnn_r50_fpn_20e_coco.py')","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:31.083285Z","iopub.execute_input":"2021-12-27T20:09:31.083754Z","iopub.status.idle":"2021-12-27T20:09:31.115636Z","shell.execute_reply.started":"2021-12-27T20:09:31.083721Z","shell.execute_reply":"2021-12-27T20:09:31.114874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(cfg.pretty_text)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T16:50:52.21054Z","iopub.execute_input":"2021-11-14T16:50:52.212363Z","iopub.status.idle":"2021-11-14T16:50:52.937165Z","shell.execute_reply.started":"2021-11-14T16:50:52.212284Z","shell.execute_reply":"2021-11-14T16:50:52.936104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir /kaggle/working/mmdetection/configs/sartorius/","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:31.116922Z","iopub.execute_input":"2021-12-27T20:09:31.117333Z","iopub.status.idle":"2021-12-27T20:09:31.255022Z","shell.execute_reply.started":"2021-12-27T20:09:31.117291Z","shell.execute_reply":"2021-12-27T20:09:31.253967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://download.openmmlab.com/mmdetection/v2.0/ms_rcnn/ms_rcnn_x101_32x4d_fpn_1x_coco/ms_rcnn_x101_32x4d_fpn_1x_coco_20200206-81fd1740.pth -P /kaggle/working/mmdetection/configs/sartorius/","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:09:31.256828Z","iopub.execute_input":"2021-12-27T20:09:31.257153Z","iopub.status.idle":"2021-12-27T20:10:13.044247Z","shell.execute_reply.started":"2021-12-27T20:09:31.25707Z","shell.execute_reply":"2021-12-27T20:10:13.043379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-12-18T07:08:18.321597Z","iopub.execute_input":"2021-12-18T07:08:18.321872Z","iopub.status.idle":"2021-12-18T07:08:18.326332Z","shell.execute_reply.started":"2021-12-18T07:08:18.321834Z","shell.execute_reply":"2021-12-18T07:08:18.325401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg.dataset_type = 'CocoDataset'\ncfg.classes = '/kaggle/working/labels.txt'\ncfg.data_root = '/kaggle/working'\n\n# for head in cfg.model.roi_head.bbox_head:\n#     head.num_classes = 3\ncfg.model.roi_head.bbox_head.num_classes=3\n# for head in cfg.model.roi_head.mask_head:\n#     head.num_classes = 3\n    \n# cfg.model.roi_head.mask_head.semantic_head.num_classes=3\ncfg.model.roi_head.mask_head.num_classes=3\n\ncfg.model.roi_head.mask_iou_head.num_classes=3\n\n\ncfg.data.test.type = 'CocoDataset'\ncfg.data.test.classes = 'labels.txt'\ncfg.data.test.data_root = '/kaggle/working'\ncfg.data.test.ann_file = '/kaggle/input/k/vexxingbanana/sartorius-coco-dataset-notebook/val_dataset.json'\ncfg.data.test.img_prefix = ''\n\ncfg.data.train.type = 'CocoDataset'\ncfg.data.train.data_root = '/kaggle/working'\ncfg.data.train.ann_file = '/kaggle/input/k/vexxingbanana/sartorius-coco-dataset-notebook/train_dataset.json'\ncfg.data.train.img_prefix = ''\ncfg.data.train.classes = 'labels.txt'\n\ncfg.data.val.type = 'CocoDataset'\ncfg.data.val.data_root = '/kaggle/working'\ncfg.data.val.ann_file = '/kaggle/input/k/vexxingbanana/sartorius-coco-dataset-notebook/val_dataset.json'\ncfg.data.val.img_prefix = ''\ncfg.data.val.classes = 'labels.txt'\n\nalbu_train_transforms = [\n    dict(type='ShiftScaleRotate', shift_limit=0.0625,\n         scale_limit=0.15, rotate_limit=15, p=0.4),\n    dict(type='RandomBrightnessContrast', brightness_limit=0.2,\n         contrast_limit=0.2, p=0.5),\n#     dict(type='IAAAffine', shear=(-10.0, 10.0), p=0.4),\n#     dict(type='CLAHE', p=0.5),\n    dict(\n        type=\"OneOf\",\n        transforms=[\n            dict(type=\"GaussianBlur\", p=1.0, blur_limit=7),\n            dict(type=\"MedianBlur\", p=1.0, blur_limit=7),\n        ],\n        p=0.4,\n    ),\n]\n\ncfg.train_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n    dict(type='Resize', img_scale=[(440, 596), (480, 650), (520, 704), (580, 785), (620, 839)], multiscale_mode='value', keep_ratio=True),\n#     dict(type='Resize', img_scale=[(880, 1192), (960, 130), (1040, 1408), (1160, 1570), (1240, 1678)], multiscale_mode='value', keep_ratio=True),\n#     dict(type='Resize', img_scale=[(880, 1192), (960, 130), (1040, 1408), (1160, 1570), (1240, 1678)]),\n#     dict(type='Resize', img_scale=(1333, 800)),\n    \n\n    dict(type='RandomFlip', flip_ratio=0.5),\n\n    dict(\n        type='Albu',\n        transforms=albu_train_transforms,\n        bbox_params=dict(\n        type='BboxParams',\n        format='pascal_voc',\n        label_fields=['gt_labels'],\n        min_visibility=0.0,\n        filter_lost_elements=True),\n        keymap=dict(img='image', gt_bboxes='bboxes', gt_masks='masks'),\n        update_pad_shape=False,\n        skip_img_without_anno=True),\n    dict(\n        type='Normalize',\n        mean=[128, 128, 128],\n        std=[11.58, 11.58, 11.58],\n        to_rgb=True),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'), \n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_masks', 'gt_labels'])\n]\n\ncfg.val_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=[(880, 1192), (960, 130), (1040, 1408), (1160, 1570), (1240, 1678)],\n#         img_scale = [(1333, 800), (1690, 960)],\n#         img_scale=(1333, 800),\n#         img_scale = (520, 704),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[128, 128, 128],\n                std=[11.58, 11.58, 11.58],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\n\n\ncfg.test_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=[(880, 1192), (960, 130), (1040, 1408), (1160, 1570), (1240, 1678)],\n#         img_scale=[(1333, 800), (1690, 960)],\n#         img_scale=(1333, 800),\n        \n#         img_scale = (520, 704),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[128, 128, 128],\n                std=[11.58, 11.58, 11.58],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\n\ncfg.data.train.pipeline = cfg.train_pipeline\ncfg.data.val.pipeline = cfg.val_pipeline\ncfg.data.test.pipeline = cfg.test_pipeline\n\n\ncfg.model.test_cfg.rcnn.max_per_img = 800\n\n# cfg.load_from = '../input/htc-checkpoint-resnext101/htc_x101_64x4d_fpn_dconv_c3-c5_mstrain_400_1400_16x1_20e_coco_20200312-946fd751.pth'\ncfg.load_from = '/kaggle/working/mmdetection/configs/sartorius/ms_rcnn_x101_32x4d_fpn_1x_coco_20200206-81fd1740.pth'\n# cfg.load_from = '../input/cascade-mask-rcnn-r50/cascade_mask_rcnn_r50_fpn_20e_coco_bbox_mAP-0.419__segm_mAP-0.365_20200504_174711-4af8e66e.pth'\n\ncfg.work_dir = '/kaggle/working/model_output'\n\ncfg.optimizer.lr = 0.02 / 8\n# cfg.optimizer = dict(type='Adam', lr=0.01, weight_decay=0.0001) #mod\ncfg.lr_config = dict(\n    policy='CosineAnnealing',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=0.001,\n    min_lr_ratio=1e-5)\n\ncfg.data.samples_per_gpu = 2\ncfg.data.workers_per_gpu = 2\n\ncfg.evaluation.metric = 'segm'\ncfg.evaluation.interval = 1\n\ncfg.checkpoint_config.interval = 1\ncfg.runner.max_epochs = 21\ncfg.log_config.interval = 144\n\n# cfg.model.rpn_head.anchor_generator.base_sizes = [4, 9, 17, 31, 64]\n# cfg.model.rpn_head.anchor_generator.strides = [4, 8, 16, 32, 64]\n\n\ncfg.seed = 0\nset_random_seed(0, deterministic=False)\ncfg.gpu_ids = range(1)\ncfg.fp16 = dict(loss_scale=512.0)\nmeta = dict()\nmeta['config'] = cfg.pretty_text\n\n# print(f'Config:\\n{cfg.pretty_text}')","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:44:55.540801Z","iopub.execute_input":"2021-12-27T20:44:55.541076Z","iopub.status.idle":"2021-12-27T20:44:57.9236Z","shell.execute_reply.started":"2021-12-27T20:44:55.541047Z","shell.execute_reply":"2021-12-27T20:44:57.922772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training**","metadata":{}},{"cell_type":"code","source":"datasets = [build_dataset(cfg.data.train)]\nmodel = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\nmodel.CLASSES = datasets[0].CLASSES\n\nmmcv.mkdir_or_exist(os.path.abspath(cfg.work_dir))\ntrain_detector(model, datasets, cfg, distributed=False, validate=True, meta=meta)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T20:46:02.284747Z","iopub.execute_input":"2021-12-27T20:46:02.285014Z","iopub.status.idle":"2021-12-27T20:58:37.21277Z","shell.execute_reply.started":"2021-12-27T20:46:02.284985Z","shell.execute_reply":"2021-12-27T20:58:37.211451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# bygyugyubnhgyuhnuhyuhgu9hgu9hug9yg9yg9abfiqubefiqbfeiuqbwfibqwifubqwifb andjaskd asjdnjkasnd ajsndjas njaskdnjkasndjn nkjnknkjn jasndjn jnsakjndkjn","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# igiygbutftuv uftufv uftv ftovl fot7lv ofvhk","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -GFlash --color ./model_output","metadata":{"execution":{"iopub.status.busy":"2021-12-18T08:03:19.684417Z","iopub.execute_input":"2021-12-18T08:03:19.684699Z","iopub.status.idle":"2021-12-18T08:03:19.919772Z","shell.execute_reply.started":"2021-12-18T08:03:19.684661Z","shell.execute_reply":"2021-12-18T08:03:19.9189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg.load_from = '/kaggle/working/model_output/epoch_9.pth'\ncfg.work_dir = '/kaggle/working/finetune_output'\ncfg.optimizer.lr = 0.02 / 32\ncfg.lr_config = dict(\n    policy='CosineAnnealing', \n    by_epoch=False,\n    warmup='linear', \n    warmup_iters=1, \n    warmup_ratio=0.001,\n    min_lr=1e-09)\ncfg.runner.max_epochs = 6\n\nmodel = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\nmodel.CLASSES = datasets[0].CLASSES\n\nmmcv.mkdir_or_exist(os.path.abspath(cfg.work_dir))\ntrain_detector(model, datasets, cfg, distributed=False, validate=True, meta=meta)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T08:03:53.578293Z","iopub.execute_input":"2021-12-18T08:03:53.578934Z","iopub.status.idle":"2021-12-18T08:04:13.800324Z","shell.execute_reply.started":"2021-12-18T08:03:53.578895Z","shell.execute_reply":"2021-12-18T08:04:13.798955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}