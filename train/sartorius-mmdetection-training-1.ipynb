{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Coco Dataset Notebook and Inference Notebook**","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/vexxingbanana/sartorius-coco-dataset-notebook\n\nhttps://www.kaggle.com/vexxingbanana/mmdetection-neuron-inference","metadata":{}},{"cell_type":"markdown","source":"# **References**","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/dschettler8845/sartorius-segmentation-eda-and-baseline\n\nhttps://www.kaggle.com/ihelon/cell-segmentation-run-length-decoding\n\nhttps://www.kaggle.com/stainsby/fast-tested-rle\n\nhttps://www.kaggle.com/paulorzp/run-length-encode-and-decode\n\nhttps://www.kaggle.com/awsaf49/sartorius-mmdetection-infer\n\nhttps://www.kaggle.com/awsaf49/sartorius-mmdetection-train\n\nhttps://www.kaggle.com/evancofsky/sartorius-torch-lightning-mask-r-cnn/notebook","metadata":{}},{"cell_type":"markdown","source":"# Notes","metadata":{}},{"cell_type":"markdown","source":"* Trying out more epochs, added more augmentations, increased batch size to 2, and using validation dataset.\n* Added mixed precision, reduced epochs back to 12, removed CLAHE augmentation.\n* Increased confidence on inference of bboxes to 0.5, removed validation.\n* Trying out more epochs, added back 5% validation, changed normalization to the dataset, changed to 3 classes.","metadata":{}},{"cell_type":"markdown","source":"Please consider upvoting if you find this helpful. :)","metadata":{}},{"cell_type":"markdown","source":"# **Install MMDetection and MMDetection-Compatible Torch**","metadata":{}},{"cell_type":"code","source":"!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torch-1.7.0+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torchvision-0.8.1+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torchaudio-0.7.0-cp37-cp37m-linux_x86_64.whl' --no-deps","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:17:14.875961Z","iopub.execute_input":"2021-12-27T14:17:14.876345Z","iopub.status.idle":"2021-12-27T14:18:26.362769Z","shell.execute_reply.started":"2021-12-27T14:17:14.876239Z","shell.execute_reply":"2021-12-27T14:18:26.361626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install '/kaggle/input/mmdetectionv2140/addict-2.4.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/yapf-0.31.0-py2.py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/terminal-0.4.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/terminaltables-3.1.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/mmcv_full-1_3_8-cu110-torch1_7_0/mmcv_full-1.3.8-cp37-cp37m-manylinux1_x86_64.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/pycocotools-2.0.2/pycocotools-2.0.2' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/mmpycocotools-12.0.3/mmpycocotools-12.0.3' --no-deps\n\n!rm -rf mmdetection\n\n!cp -r /kaggle/input/mmdetectionv2140/mmdetection-2.14.0 /kaggle/working/\n!mv /kaggle/working/mmdetection-2.14.0 /kaggle/working/mmdetection\n%cd /kaggle/working/mmdetection\n!pip install -e .","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:18:26.366796Z","iopub.execute_input":"2021-12-27T14:18:26.367112Z","iopub.status.idle":"2021-12-27T14:19:29.371998Z","shell.execute_reply.started":"2021-12-27T14:18:26.367075Z","shell.execute_reply":"2021-12-27T14:19:29.370805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Import Libraries** ","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport sklearn\nimport torchvision\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport PIL\nimport json\nfrom PIL import Image, ImageEnhance\nimport albumentations as A\nimport mmdet\nimport mmcv\nfrom albumentations.pytorch import ToTensorV2\nimport seaborn as sns\nimport glob\nfrom pathlib import Path\nimport pycocotools\nfrom pycocotools import mask\nimport numpy.random\nimport random\nimport cv2\nimport re\nfrom mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector\nfrom mmdet.apis import inference_detector, init_detector, show_result_pyplot, set_random_seed","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-27T14:22:08.850384Z","iopub.execute_input":"2021-12-27T14:22:08.850944Z","iopub.status.idle":"2021-12-27T14:22:33.305827Z","shell.execute_reply.started":"2021-12-27T14:22:08.85091Z","shell.execute_reply":"2021-12-27T14:22:33.304582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd ..","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:33.308516Z","iopub.execute_input":"2021-12-27T14:22:33.308875Z","iopub.status.idle":"2021-12-27T14:22:33.318383Z","shell.execute_reply.started":"2021-12-27T14:22:33.308833Z","shell.execute_reply":"2021-12-27T14:22:33.317321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_WIDTH = 704\nIMG_HEIGHT = 520","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:33.320464Z","iopub.execute_input":"2021-12-27T14:22:33.321167Z","iopub.status.idle":"2021-12-27T14:22:33.331942Z","shell.execute_reply.started":"2021-12-27T14:22:33.321079Z","shell.execute_reply":"2021-12-27T14:22:33.330986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Helper Functions**","metadata":{}},{"cell_type":"code","source":"def rle_decode(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\ndef flatten_l_o_l(nested_list):\n    \"\"\" Flatten a list of lists \"\"\"\n    return [item for sublist in nested_list for item in sublist]\n\n\ndef load_json_to_dict(json_path):\n    \"\"\" tbd \"\"\"\n    with open(json_path) as json_file:\n        data = json.load(json_file)\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:33.336196Z","iopub.execute_input":"2021-12-27T14:22:33.337045Z","iopub.status.idle":"2021-12-27T14:22:33.350341Z","shell.execute_reply.started":"2021-12-27T14:22:33.337001Z","shell.execute_reply":"2021-12-27T14:22:33.348963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img_and_mask(img_path, annotation, width, height):\n    \"\"\" Capture the relevant image array as well as the image mask \"\"\"\n    img_mask = np.zeros((height, width), dtype=np.uint8)\n    for i, annot in enumerate(annotation): \n        img_mask = np.where(rle_decode(annot, (height, width))!=0, i, img_mask)\n    img = cv2.imread(img_path)[..., ::-1]\n    return img[..., 0], img_mask\n\ndef plot_img_and_mask(img, mask, invert_img=True, boost_contrast=True):\n    \"\"\" Function to take an image and the corresponding mask and plot\n    \n    Args:\n        img (np.arr): 1 channel np arr representing the image of cellular structures\n        mask (np.arr): 1 channel np arr representing the instance masks (incrementing by one)\n        invert_img (bool, optional): Whether or not to invert the base image\n        boost_contrast (bool, optional): Whether or not to boost contrast of the base image\n        \n    Returns:\n        None; Plots the two arrays and overlays them to create a merged image\n    \"\"\"\n    plt.figure(figsize=(20,10))\n    \n    plt.subplot(1,3,1)\n    _img = np.tile(np.expand_dims(img, axis=-1), 3)\n    \n    # Flip black-->white ... white-->black\n    if invert_img:\n        _img = _img.max()-_img\n        \n    if boost_contrast:\n        _img = np.asarray(ImageEnhance.Contrast(Image.fromarray(_img)).enhance(16))\n        \n    plt.imshow(_img)\n    plt.axis(False)\n    plt.title(\"Cell Image\", fontweight=\"bold\")\n    \n    plt.subplot(1,3,2)\n    _mask = np.zeros_like(_img)\n    _mask[..., 0] = mask\n    plt.imshow(mask, cmap='rainbow')\n    plt.axis(False)\n    plt.title(\"Instance Segmentation Mask\", fontweight=\"bold\")\n    \n    merged = cv2.addWeighted(_img, 0.75, np.clip(_mask, 0, 1)*255, 0.25, 0.0,)\n    plt.subplot(1,3,3)\n    plt.imshow(merged)\n    plt.axis(False)\n    plt.title(\"Cell Image w/ Instance Segmentation Mask Overlay\", fontweight=\"bold\")\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:33.352164Z","iopub.execute_input":"2021-12-27T14:22:33.352814Z","iopub.status.idle":"2021-12-27T14:22:33.370165Z","shell.execute_reply.started":"2021-12-27T14:22:33.352753Z","shell.execute_reply":"2021-12-27T14:22:33.368844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def polygonFromMask(maskedArr, idx):\n    \n    # adapted from https://github.com/hazirbas/coco-json-converter/blob/master/generate_coco_json.py\n    contours, _ = cv2.findContours(maskedArr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    segmentation = []\n    valid_poly = 0\n    for contour in contours:\n        \n    # Valid polygons have >= 6 coordinates (3 points)\n        if contour.size >= 6:\n            segmentation.append(contour.astype(float).flatten().tolist())\n            valid_poly += 1\n    if valid_poly == 0:\n        raise ValueError(idx)\n    \n    return [segmentation]","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:33.372199Z","iopub.execute_input":"2021-12-27T14:22:33.372796Z","iopub.status.idle":"2021-12-27T14:22:33.386468Z","shell.execute_reply.started":"2021-12-27T14:22:33.372726Z","shell.execute_reply":"2021-12-27T14:22:33.385307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Visualizations**","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/sartorius-cell-instance-segmentation/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:33.388449Z","iopub.execute_input":"2021-12-27T14:22:33.388842Z","iopub.status.idle":"2021-12-27T14:22:33.990211Z","shell.execute_reply.started":"2021-12-27T14:22:33.388786Z","shell.execute_reply":"2021-12-27T14:22:33.98918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:33.992156Z","iopub.execute_input":"2021-12-27T14:22:33.992535Z","iopub.status.idle":"2021-12-27T14:22:34.022448Z","shell.execute_reply.started":"2021-12-27T14:22:33.992475Z","shell.execute_reply":"2021-12-27T14:22:34.021287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lines = []\nfor f in train_df.itertuples():\n    lines.append('/kaggle/input/sartorius-cell-instance-segmentation/train/' + f[1] + '.png')","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:34.024376Z","iopub.execute_input":"2021-12-27T14:22:34.024743Z","iopub.status.idle":"2021-12-27T14:22:34.213744Z","shell.execute_reply.started":"2021-12-27T14:22:34.024684Z","shell.execute_reply":"2021-12-27T14:22:34.212763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lins = pd.Series(lines, name='img_path')","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:34.218144Z","iopub.execute_input":"2021-12-27T14:22:34.218412Z","iopub.status.idle":"2021-12-27T14:22:34.229924Z","shell.execute_reply.started":"2021-12-27T14:22:34.218381Z","shell.execute_reply":"2021-12-27T14:22:34.228607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.concat([train_df, lins], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:34.231894Z","iopub.execute_input":"2021-12-27T14:22:34.232671Z","iopub.status.idle":"2021-12-27T14:22:34.257619Z","shell.execute_reply.started":"2021-12-27T14:22:34.232624Z","shell.execute_reply":"2021-12-27T14:22:34.256608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp_df = train_df.drop_duplicates(subset=[\"id\", \"img_path\"]).reset_index(drop=True)\ntmp_df[\"annotation\"] = train_df.groupby(\"id\")[\"annotation\"].agg(list).reset_index(drop=True)\ntrain_df = tmp_df.copy()","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:34.25944Z","iopub.execute_input":"2021-12-27T14:22:34.259806Z","iopub.status.idle":"2021-12-27T14:22:34.354769Z","shell.execute_reply.started":"2021-12-27T14:22:34.25976Z","shell.execute_reply":"2021-12-27T14:22:34.353796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:34.356595Z","iopub.execute_input":"2021-12-27T14:22:34.356915Z","iopub.status.idle":"2021-12-27T14:22:34.380196Z","shell.execute_reply.started":"2021-12-27T14:22:34.356871Z","shell.execute_reply":"2021-12-27T14:22:34.378896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_mask(idx):\n    im, mk = get_img_and_mask(**train_df[[\"img_path\", \"annotation\", \"width\", \"height\"]].iloc[idx].to_dict())\n    plot_img_and_mask(im, mk)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:34.381857Z","iopub.execute_input":"2021-12-27T14:22:34.382655Z","iopub.status.idle":"2021-12-27T14:22:34.390185Z","shell.execute_reply.started":"2021-12-27T14:22:34.382604Z","shell.execute_reply":"2021-12-27T14:22:34.38902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_mask(0)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:34.391544Z","iopub.execute_input":"2021-12-27T14:22:34.392347Z","iopub.status.idle":"2021-12-27T14:22:35.320695Z","shell.execute_reply.started":"2021-12-27T14:22:34.392295Z","shell.execute_reply":"2021-12-27T14:22:35.319567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_mask(1)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:35.322034Z","iopub.execute_input":"2021-12-27T14:22:35.322417Z","iopub.status.idle":"2021-12-27T14:22:36.035271Z","shell.execute_reply.started":"2021-12-27T14:22:35.32238Z","shell.execute_reply":"2021-12-27T14:22:36.034407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_mask(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:36.036973Z","iopub.execute_input":"2021-12-27T14:22:36.039714Z","iopub.status.idle":"2021-12-27T14:22:36.734048Z","shell.execute_reply.started":"2021-12-27T14:22:36.03967Z","shell.execute_reply":"2021-12-27T14:22:36.732337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, val_df = train_test_split(train_df, train_size=0.95, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:36.735922Z","iopub.execute_input":"2021-12-27T14:22:36.736442Z","iopub.status.idle":"2021-12-27T14:22:36.74661Z","shell.execute_reply.started":"2021-12-27T14:22:36.7364Z","shell.execute_reply":"2021-12-27T14:22:36.745485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:36.748324Z","iopub.execute_input":"2021-12-27T14:22:36.748977Z","iopub.status.idle":"2021-12-27T14:22:36.757811Z","shell.execute_reply.started":"2021-12-27T14:22:36.748935Z","shell.execute_reply":"2021-12-27T14:22:36.756807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile labels.txt\nshsy5y\ncort\nastro","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:36.760089Z","iopub.execute_input":"2021-12-27T14:22:36.760959Z","iopub.status.idle":"2021-12-27T14:22:36.770924Z","shell.execute_reply.started":"2021-12-27T14:22:36.760913Z","shell.execute_reply":"2021-12-27T14:22:36.769581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Config**","metadata":{}},{"cell_type":"code","source":"from mmcv import Config\n# cfg = Config.fromfile('/kaggle/working/mmdetection/configs/htc/htc_x101_64x4d_fpn_dconv_c3-c5_mstrain_400_1400_16x1_20e_coco.py')\ncfg = Config.fromfile('/kaggle/working/mmdetection/configs/ms_rcnn/ms_rcnn_x101_32x4d_fpn_1x_coco.py')\n# cfg = Config.fromfile('/kaggle/working/mmdetection/configs/ms_rcnn/ms_rcnn_x101_64x4d_fpn_2x_coco.py')\n\n# cfg = Config.fromfile('/kaggle/working/mmdetection/configs/cascade_rcnn/cascade_mask_rcnn_r50_fpn_20e_coco.py')","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:36.773037Z","iopub.execute_input":"2021-12-27T14:22:36.77372Z","iopub.status.idle":"2021-12-27T14:22:36.812782Z","shell.execute_reply.started":"2021-12-27T14:22:36.773674Z","shell.execute_reply":"2021-12-27T14:22:36.811811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(cfg.pretty_text)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T04:48:02.367362Z","iopub.execute_input":"2021-12-26T04:48:02.367861Z","iopub.status.idle":"2021-12-26T04:48:03.092525Z","shell.execute_reply.started":"2021-12-26T04:48:02.367823Z","shell.execute_reply":"2021-12-26T04:48:03.091806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = dict(\n#     type='MaskScoringRCNN',\n#     backbone=dict(\n#         type='ResNeXt',\n#         depth=101,\n#         num_stages=4,\n#         out_indices=(0, 1, 2, 3),\n#         frozen_stages=1,\n#         norm_cfg=dict(type='BN', requires_grad=True),\n#         norm_eval=True,\n#         style='pytorch',\n#         init_cfg=dict(\n#             type='Pretrained', checkpoint='open-mmlab://resnext101_64x4d'), # mod\n#         groups=64,\n#         base_width=4),\n#     neck=dict(\n#         type='FPN',\n#         in_channels=[256, 512, 1024, 2048],\n#         out_channels=256,\n#         num_outs=5),\n#     rpn_head=dict(\n#         type='RPNHead',\n#         in_channels=256,\n#         feat_channels=256,\n#         anchor_generator=dict(\n#             type='AnchorGenerator',\n#             scales=[8],\n#             ratios=[0.5, 1.0, 2.0],\n#             strides=[4, 8, 16, 32, 64]),\n#         bbox_coder=dict(\n#             type='DeltaXYWHBBoxCoder',\n#             target_means=[0.0, 0.0, 0.0, 0.0],\n#             target_stds=[1.0, 1.0, 1.0, 1.0]),\n#         loss_cls=dict(\n#             type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n#         loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n#     roi_head=dict(\n#         type='MaskScoringRoIHead',\n#         bbox_roi_extractor=dict(\n#             type='SingleRoIExtractor',\n#             roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n#             out_channels=256,\n#             featmap_strides=[4, 8, 16, 32]),\n#         bbox_head=dict(\n#             type='Shared2FCBBoxHead',\n#             in_channels=256,\n#             fc_out_channels=1024,\n#             roi_feat_size=7,\n#             num_classes=80,\n#             bbox_coder=dict(\n#                 type='DeltaXYWHBBoxCoder',\n#                 target_means=[0.0, 0.0, 0.0, 0.0],\n#                 target_stds=[0.1, 0.1, 0.2, 0.2]),\n#             reg_class_agnostic=False,\n#             loss_cls=dict(\n#                 type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n#             loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n#         mask_roi_extractor=dict(\n#             type='SingleRoIExtractor',\n#             roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n#             out_channels=256,\n#             featmap_strides=[4, 8, 16, 32]),\n#         mask_head=dict(\n#             type='FCNMaskHead',\n#             num_convs=4,\n#             in_channels=256,\n#             conv_out_channels=256,\n#             num_classes=80,\n#             loss_mask=dict(\n#                 type='CrossEntropyLoss', use_mask=True, loss_weight=1.0)),\n#         mask_iou_head=dict(\n#             type='MaskIoUHead',\n#             num_convs=4,\n#             num_fcs=2,\n#             roi_feat_size=14,\n#             in_channels=256,\n#             conv_out_channels=256,\n#             fc_out_channels=1024,\n#             num_classes=80)),\n#     train_cfg=dict(\n#         rpn=dict(\n#             assigner=dict(\n#                 type='MaxIoUAssigner',\n#                 pos_iou_thr=0.7,\n#                 neg_iou_thr=0.3,\n#                 min_pos_iou=0.3,\n#                 match_low_quality=True,\n#                 ignore_iof_thr=-1),\n#             sampler=dict(\n#                 type='RandomSampler',\n#                 num=256,\n#                 pos_fraction=0.5,\n#                 neg_pos_ub=-1,\n#                 add_gt_as_proposals=False),\n#             allowed_border=-1,\n#             pos_weight=-1,\n#             debug=False),\n#         rpn_proposal=dict(\n#             nms_pre=2000,\n#             max_per_img=1000,\n#             nms=dict(type='nms', iou_threshold=0.7),\n#             min_bbox_size=0),\n#         rcnn=dict(\n#             assigner=dict(\n#                 type='MaxIoUAssigner',\n#                 pos_iou_thr=0.5,\n#                 neg_iou_thr=0.5,\n#                 min_pos_iou=0.5,\n#                 match_low_quality=True,\n#                 ignore_iof_thr=-1),\n#             sampler=dict(\n#                 type='RandomSampler',\n#                 num=512,\n#                 pos_fraction=0.25,\n#                 neg_pos_ub=-1,\n#                 add_gt_as_proposals=True),\n#             mask_size=28,\n#             pos_weight=-1,\n#             debug=False,\n#             mask_thr_binary=0.5)),\n#     test_cfg=dict(\n#         rpn=dict(\n#             nms_pre=1000,\n#             max_per_img=1000,\n#             nms=dict(type='nms', iou_threshold=0.5),\n#             min_bbox_size=0),\n#         rcnn=dict(\n#             score_thr=0.05,\n#             nms=dict(type='nms', iou_threshold=0.5),\n#             max_per_img=100,\n#             mask_thr_binary=0.5)))\n# dataset_type = 'CocoDataset'\n# data_root = 'data/coco/'\n# img_norm_cfg = dict(\n#     mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n\n# train_pipeline = [\n#     dict(type='LoadImageFromFile'),\n#     dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n#     dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n#     dict(type='RandomFlip', flip_ratio=0.5),\n#     dict(\n#         type='Normalize',\n#         mean=[123.675, 116.28, 103.53],\n#         std=[58.395, 57.12, 57.375],\n#         to_rgb=True),\n#     dict(type='Pad', size_divisor=32),\n#     dict(type='DefaultFormatBundle'),\n#     dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n# ]\n# test_pipeline = [\n#     dict(type='LoadImageFromFile'),\n#     dict(\n#         type='MultiScaleFlipAug',\n#         img_scale=(1333, 800),\n#         flip=False,\n#         transforms=[\n#             dict(type='Resize', keep_ratio=True),\n#             dict(type='RandomFlip'),\n#             dict(\n#                 type='Normalize',\n#                 mean=[123.675, 116.28, 103.53],\n#                 std=[58.395, 57.12, 57.375],\n#                 to_rgb=True),\n#             dict(type='Pad', size_divisor=32),\n#             dict(type='ImageToTensor', keys=['img']),\n#             dict(type='Collect', keys=['img'])\n#         ])\n# ]\n# data = dict(\n#     samples_per_gpu=2,\n#     workers_per_gpu=2,\n#     train=dict(\n#         type='CocoDataset',\n#         ann_file='data/coco/annotations/instances_train2017.json',\n#         img_prefix='data/coco/train2017/',\n#         pipeline=[\n#             dict(type='LoadImageFromFile'),\n#             dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n#             dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n#             dict(type='RandomFlip', flip_ratio=0.5),\n#             dict(\n#                 type='Normalize',\n#                 mean=[123.675, 116.28, 103.53],\n#                 std=[58.395, 57.12, 57.375],\n#                 to_rgb=True),\n#             dict(type='Pad', size_divisor=32),\n#             dict(type='DefaultFormatBundle'),\n#             dict(\n#                 type='Collect',\n#                 keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n#         ]),\n#     val=dict(\n#         type='CocoDataset',\n#         ann_file='data/coco/annotations/instances_val2017.json',\n#         img_prefix='data/coco/val2017/',\n#         pipeline=[\n#             dict(type='LoadImageFromFile'),\n#             dict(\n#                 type='MultiScaleFlipAug',\n#                 img_scale=(1333, 800),\n#                 flip=False,\n#                 transforms=[\n#                     dict(type='Resize', keep_ratio=True),\n#                     dict(type='RandomFlip'),\n#                     dict(\n#                         type='Normalize',\n#                         mean=[123.675, 116.28, 103.53],\n#                         std=[58.395, 57.12, 57.375],\n#                         to_rgb=True),\n#                     dict(type='Pad', size_divisor=32),\n#                     dict(type='ImageToTensor', keys=['img']),\n#                     dict(type='Collect', keys=['img'])\n#                 ])\n#         ]),\n#     test=dict(\n#         type='CocoDataset',\n#         ann_file='data/coco/annotations/instances_val2017.json',\n#         img_prefix='data/coco/val2017/',\n#         pipeline=[\n#             dict(type='LoadImageFromFile'),\n#             dict(\n#                 type='MultiScaleFlipAug',\n#                 img_scale=(1333, 800),\n#                 flip=False,\n#                 transforms=[\n#                     dict(type='Resize', keep_ratio=True),\n#                     dict(type='RandomFlip'),\n#                     dict(\n#                         type='Normalize',\n#                         mean=[123.675, 116.28, 103.53],\n#                         std=[58.395, 57.12, 57.375],\n#                         to_rgb=True),\n#                     dict(type='Pad', size_divisor=32),\n#                     dict(type='ImageToTensor', keys=['img']),\n#                     dict(type='Collect', keys=['img'])\n#                 ])\n#         ]))\n# evaluation = dict(metric=['bbox', 'segm'])\n# # optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n# optimizer = dict(type='Adam', lr=0.02, momentum=0.9, weight_decay=0.0001) #mod\n# optimizer_config = dict(grad_clip=None)\n# # lr_config = dict(\n# #     policy='step',\n# #     warmup='linear',\n# #     warmup_iters=500,\n# #     warmup_ratio=0.001,\n# #     step=[8, 11])\n# lr_config = dict(\n#     policy='CosineAnnealing',\n#     warmup='linear',\n#     warmup_iters=500,\n#     warmup_ratio=0.001,\n#     min_lr_ratio=1e-5,\n#     step=[8, 11])\n# runner = dict(type='EpochBasedRunner', max_epochs=25) #mod\n# checkpoint_config = dict(interval=1)\n# log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])\n# custom_hooks = [dict(type='NumClassCheckHook')]\n# dist_params = dict(backend='nccl')\n# log_level = 'INFO'\n# load_from = None\n# resume_from = None\n# workflow = [('train', 1)]","metadata":{"execution":{"iopub.status.busy":"2021-12-26T04:48:03.094031Z","iopub.execute_input":"2021-12-26T04:48:03.094709Z","iopub.status.idle":"2021-12-26T04:48:03.116274Z","shell.execute_reply.started":"2021-12-26T04:48:03.09467Z","shell.execute_reply":"2021-12-26T04:48:03.114331Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# optimizer = dict(type='Adam', lr=0.02, momentum=0.9, weight_decay=0.0001) #mod\n\n\n# lr_config = dict(\n#     policy='CosineAnnealing',\n#     warmup='linear',\n#     warmup_iters=500,\n#     warmup_ratio=0.001,\n#     min_lr_ratio=1e-5,\n#     step=[8, 11])\n\n# runner = dict(type='EpochBasedRunner', max_epochs=25) #mod\n","metadata":{"execution":{"iopub.status.busy":"2021-12-26T04:48:03.119358Z","iopub.execute_input":"2021-12-26T04:48:03.120607Z","iopub.status.idle":"2021-12-26T04:48:03.136183Z","shell.execute_reply.started":"2021-12-26T04:48:03.120518Z","shell.execute_reply":"2021-12-26T04:48:03.132237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir /kaggle/working/mmdetection/configs/sartorius/","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:36.815037Z","iopub.execute_input":"2021-12-27T14:22:36.815392Z","iopub.status.idle":"2021-12-27T14:22:36.958239Z","shell.execute_reply.started":"2021-12-27T14:22:36.815348Z","shell.execute_reply":"2021-12-27T14:22:36.957003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for backbone 2x 64_4d\n# !wget https://download.openmmlab.com/mmdetection/v2.0/ms_rcnn/ms_rcnn_x101_64x4d_fpn_2x_coco/ms_rcnn_x101_64x4d_fpn_2x_coco_20200308-02a445e2.pth -P /kaggle/working/mmdetection/configs/sartorius/\n# for backbone 2x 32_4d\n!wget https://download.openmmlab.com/mmdetection/v2.0/ms_rcnn/ms_rcnn_x101_32x4d_fpn_1x_coco/ms_rcnn_x101_32x4d_fpn_1x_coco_20200206-81fd1740.pth -P /kaggle/working/mmdetection/configs/sartorius/","metadata":{"execution":{"iopub.status.busy":"2021-12-27T14:22:36.960879Z","iopub.execute_input":"2021-12-27T14:22:36.961611Z","iopub.status.idle":"2021-12-27T14:23:17.422205Z","shell.execute_reply.started":"2021-12-27T14:22:36.961543Z","shell.execute_reply":"2021-12-27T14:23:17.420935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg.dataset_type = 'CocoDataset'\ncfg.classes = '/kaggle/working/labels.txt'\ncfg.data_root = '/kaggle/working'\n\n# for head in cfg.model.roi_head.bbox_head:\n#     head.num_classes = 3\ncfg.model.roi_head.bbox_head.num_classes=3\n# for head in cfg.model.roi_head.mask_head:\n#     head.num_classes = 3\n    \n# cfg.model.roi_head.mask_head.semantic_head.num_classes=3\ncfg.model.roi_head.mask_head.num_classes=3\n\ncfg.model.roi_head.mask_iou_head.num_classes=3\n\n\ncfg.data.test.type = 'CocoDataset'\ncfg.data.test.classes = 'labels.txt'\ncfg.data.test.data_root = '/kaggle/working'\ncfg.data.test.ann_file = '/kaggle/input/k/vexxingbanana/sartorius-coco-dataset-notebook/val_dataset.json'\ncfg.data.test.img_prefix = ''\n\ncfg.data.train.type = 'CocoDataset'\ncfg.data.train.data_root = '/kaggle/working'\ncfg.data.train.ann_file = '/kaggle/input/k/vexxingbanana/sartorius-coco-dataset-notebook/train_dataset.json'\ncfg.data.train.img_prefix = ''\ncfg.data.train.classes = 'labels.txt'\n\ncfg.data.val.type = 'CocoDataset'\ncfg.data.val.data_root = '/kaggle/working'\ncfg.data.val.ann_file = '/kaggle/input/k/vexxingbanana/sartorius-coco-dataset-notebook/val_dataset.json'\ncfg.data.val.img_prefix = ''\ncfg.data.val.classes = 'labels.txt'\n\nalbu_train_transforms = [\n    dict(type='ShiftScaleRotate', shift_limit=0.0625,\n         scale_limit=0.15, rotate_limit=15, p=0.4)\n#     dict(type='RandomBrightnessContrast', brightness_limit=0.2,\n#          contrast_limit=0.2, p=0.5),\n# #     dict(type='IAAAffine', shear=(-10.0, 10.0), p=0.4),\n# #     dict(type='CLAHE', p=0.5),\n#     dict(\n#         type=\"OneOf\",\n#         transforms=[\n#             dict(type=\"GaussianBlur\", p=1.0, blur_limit=7),\n#             dict(type=\"MedianBlur\", p=1.0, blur_limit=7),\n#         ],\n#         p=0.4,\n#     ),\n]\n\ncfg.train_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n#     dict(type='Resize', img_scale=[(440, 596), (480, 650), (520, 704), (580, 785), (620, 839)], multiscale_mode='value', keep_ratio=True),\n#     dict(type='Resize', img_scale=[(880, 1192), (960, 130), (1040, 1408), (1160, 1570), (1240, 1678)], multiscale_mode='value', keep_ratio=True),\n    dict(type='Resize', img_scale=[(1333, 800), (1690, 960)]),\n#     dict(type='Resize', img_scale=(1333, 800)),\n    \n    \n\n    dict(type='RandomFlip', flip_ratio=0.20),\n#     dict(type='ShiftScaleRotate', shift_limit=0.0625,\n#          scale_limit=0.15, rotate_limit=15, p=0.4),\n#     dict(\n#         type='Albu',\n#         transforms=albu_train_transforms,\n#         bbox_params=dict(\n#         type='BboxParams',\n#         format='pascal_voc',\n#         label_fields=['gt_labels'],\n#         min_visibility=0.0,\n#         filter_lost_elements=True),\n#         keymap=dict(img='image', gt_bboxes='bboxes', gt_masks='masks'),\n#         update_pad_shape=False,\n#         skip_img_without_anno=True),\n    dict(\n        type='Normalize',\n        mean=[128, 128, 128],\n        std=[11.58, 11.58, 11.58],\n        to_rgb=True),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'), \n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_masks', 'gt_labels'])\n]\n\ncfg.val_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n#         img_scale=[(880, 1192), (960, 130), (1040, 1408), (1160, 1570), (1240, 1678)],\n        img_scale = [(1333, 800), (1690, 960)],\n#         img_scale=(1333, 800),\n#         img_scale = (520, 704),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip', flip_ratio=0.20),\n#             dict(type='ShiftScaleRotate', shift_limit=0.0625,\n#          scale_limit=0.15, rotate_limit=15, p=0.4),\n            dict(\n                type='Normalize',\n                mean=[128, 128, 128],\n                std=[11.58, 11.58, 11.58],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\n\n\ncfg.test_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=[(1333, 800), (1690, 960)],\n#         img_scale=(1333, 800),\n        \n#         img_scale = (520, 704),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip', flip_ratio=0.20),\n#             dict(type='ShiftScaleRotate', shift_limit=0.0625,\n#          scale_limit=0.15, rotate_limit=15, p=0.4),\n            dict(\n                type='Normalize',\n                mean=[128, 128, 128],\n                std=[11.58, 11.58, 11.58],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\n\ncfg.data.train.pipeline = cfg.train_pipeline\ncfg.data.val.pipeline = cfg.val_pipeline\ncfg.data.test.pipeline = cfg.test_pipeline\n\n\ncfg.model.test_cfg.rcnn.max_per_img = 700\n\n# cfg.load_from = '../input/htc-checkpoint-resnext101/htc_x101_64x4d_fpn_dconv_c3-c5_mstrain_400_1400_16x1_20e_coco_20200312-946fd751.pth'\n# cfg.load_from = '/kaggle/working/mmdetection/configs/sartorius/ms_rcnn_x101_32x4d_fpn_1x_coco_20200206-81fd1740.pth'\ncfg.load_from = '/kaggle/working/mmdetection/configs/sartorius/ms_rcnn_x101_32x4d_fpn_1x_coco_20200206-81fd1740.pth' # 2x 32_4d\n# cfg.load_from = '../input/cascade-mask-rcnn-r50/cascade_mask_rcnn_r50_fpn_20e_coco_bbox_mAP-0.419__segm_mAP-0.365_20200504_174711-4af8e66e.pth'\n\ncfg.work_dir = '/kaggle/working/model_output'\ncfg.optimizer = dict(type='Adam', lr=0.01, weight_decay=0.0001) #mod\ncfg.lr_config = dict(\n    policy='CosineAnnealing',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=0.001,\n    min_lr_ratio=1e-5)\n# cfg.optimizer.lr = 0.0001\n# cfg.lr_config = dict(\n#     policy='CosineAnnealing', \n#     by_epoch=False,\n#     warmup='linear', \n#     warmup_iters=125, \n#     warmup_ratio=0.001,\n#     min_lr=1e-07)\n\ncfg.data.samples_per_gpu = 2\ncfg.data.workers_per_gpu = 2\n\ncfg.evaluation.metric = 'segm'\ncfg.evaluation.interval = 1\n\ncfg.checkpoint_config.interval = 1\ncfg.runner.max_epochs = 21\ncfg.log_config.interval = 144\n\n# cfg.model.rpn_head.anchor_generator.base_sizes = [4, 9, 17, 31, 64]\n# cfg.model.rpn_head.anchor_generator.strides = [4, 8, 16, 32, 64]\n\n\ncfg.seed = 0\nset_random_seed(0, deterministic=False)\ncfg.gpu_ids = range(1)\ncfg.fp16 = dict(loss_scale=512.0)\nmeta = dict()\nmeta['config'] = cfg.pretty_text\n\n\n\nprint(f'Config:\\n{cfg.pretty_text}')","metadata":{"execution":{"iopub.status.busy":"2021-12-26T04:48:40.77531Z","iopub.execute_input":"2021-12-26T04:48:40.775876Z","iopub.status.idle":"2021-12-26T04:48:43.340825Z","shell.execute_reply.started":"2021-12-26T04:48:40.775836Z","shell.execute_reply":"2021-12-26T04:48:43.340084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training**","metadata":{}},{"cell_type":"code","source":"datasets = [build_dataset(cfg.data.train)]\nmodel = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\nmodel.CLASSES = datasets[0].CLASSES\n\nmmcv.mkdir_or_exist(os.path.abspath(cfg.work_dir))\ntrain_detector(model, datasets, cfg, distributed=False, validate=True, meta=meta)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T04:48:43.344815Z","iopub.execute_input":"2021-12-26T04:48:43.345484Z","iopub.status.idle":"2021-12-26T04:52:19.796155Z","shell.execute_reply.started":"2021-12-26T04:48:43.345443Z","shell.execute_reply":"2021-12-26T04:52:19.794767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# bygyugyubnhgyuhnuhyuhgu9hgu9hug9yg9yg9 asdnjandc aqofhoqwhfd quhfuqohwf","metadata":{"execution":{"iopub.status.busy":"2021-12-26T04:52:19.797736Z","iopub.status.idle":"2021-12-26T04:52:19.798403Z","shell.execute_reply.started":"2021-12-26T04:52:19.798154Z","shell.execute_reply":"2021-12-26T04:52:19.798178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# igiygbutftuv uftufv uftv ftovl fot7lv ofvhk","metadata":{"execution":{"iopub.status.busy":"2021-12-26T04:52:19.799751Z","iopub.status.idle":"2021-12-26T04:52:19.800425Z","shell.execute_reply.started":"2021-12-26T04:52:19.800155Z","shell.execute_reply":"2021-12-26T04:52:19.800179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -GFlash --color ./model_output","metadata":{"execution":{"iopub.status.busy":"2021-12-26T04:52:19.801828Z","iopub.status.idle":"2021-12-26T04:52:19.802469Z","shell.execute_reply.started":"2021-12-26T04:52:19.80223Z","shell.execute_reply":"2021-12-26T04:52:19.802254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cfg.load_from = '/kaggle/working/model_output/epoch_9.pth'\n# cfg.work_dir = '/kaggle/working/finetune_output'\n# cfg.optimizer.lr = 0.02 / 32\n# cfg.lr_config = dict(\n#     policy='CosineAnnealing', \n#     by_epoch=False,\n#     warmup='linear', \n#     warmup_iters=1, \n#     warmup_ratio=0.001,\n#     min_lr=1e-09)\n# cfg.runner.max_epochs = 6\n\n# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n# model.CLASSES = datasets[0].CLASSES\n\n# mmcv.mkdir_or_exist(os.path.abspath(cfg.work_dir))\n# train_detector(model, datasets, cfg, distributed=False, validate=True, meta=meta)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T18:58:52.473072Z","iopub.status.idle":"2021-12-25T18:58:52.474007Z","shell.execute_reply.started":"2021-12-25T18:58:52.473738Z","shell.execute_reply":"2021-12-25T18:58:52.473765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}