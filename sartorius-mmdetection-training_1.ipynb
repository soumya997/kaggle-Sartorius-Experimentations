{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Coco Dataset Notebook and Inference Notebook**","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/vexxingbanana/sartorius-coco-dataset-notebook\n\nhttps://www.kaggle.com/vexxingbanana/mmdetection-neuron-inference","metadata":{}},{"cell_type":"markdown","source":"# **References**","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/dschettler8845/sartorius-segmentation-eda-and-baseline\n\nhttps://www.kaggle.com/ihelon/cell-segmentation-run-length-decoding\n\nhttps://www.kaggle.com/stainsby/fast-tested-rle\n\nhttps://www.kaggle.com/paulorzp/run-length-encode-and-decode\n\nhttps://www.kaggle.com/awsaf49/sartorius-mmdetection-infer\n\nhttps://www.kaggle.com/awsaf49/sartorius-mmdetection-train\n\nhttps://www.kaggle.com/evancofsky/sartorius-torch-lightning-mask-r-cnn/notebook","metadata":{}},{"cell_type":"markdown","source":"# Notes","metadata":{}},{"cell_type":"markdown","source":"* Trying out more epochs, added more augmentations, increased batch size to 2, and using validation dataset.\n* Added mixed precision, reduced epochs back to 12, removed CLAHE augmentation.\n* Increased confidence on inference of bboxes to 0.5, removed validation.\n* Trying out more epochs, added back 5% validation, changed normalization to the dataset, changed to 3 classes.","metadata":{}},{"cell_type":"markdown","source":"Please consider upvoting if you find this helpful. :)","metadata":{}},{"cell_type":"markdown","source":"# **Install MMDetection and MMDetection-Compatible Torch**","metadata":{}},{"cell_type":"code","source":"!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torch-1.7.0+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torchvision-0.8.1+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torchaudio-0.7.0-cp37-cp37m-linux_x86_64.whl' --no-deps","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:30:16.487430Z","iopub.execute_input":"2021-12-18T05:30:16.488185Z","iopub.status.idle":"2021-12-18T05:31:23.786639Z","shell.execute_reply.started":"2021-12-18T05:30:16.488096Z","shell.execute_reply":"2021-12-18T05:31:23.785243Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install '/kaggle/input/mmdetectionv2140/addict-2.4.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/yapf-0.31.0-py2.py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/terminal-0.4.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/terminaltables-3.1.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/mmcv_full-1_3_8-cu110-torch1_7_0/mmcv_full-1.3.8-cp37-cp37m-manylinux1_x86_64.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/pycocotools-2.0.2/pycocotools-2.0.2' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/mmpycocotools-12.0.3/mmpycocotools-12.0.3' --no-deps\n\n!rm -rf mmdetection\n\n!cp -r /kaggle/input/mmdetectionv2140/mmdetection-2.14.0 /kaggle/working/\n!mv /kaggle/working/mmdetection-2.14.0 /kaggle/working/mmdetection\n%cd /kaggle/working/mmdetection\n!pip install -e .","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:31:23.790600Z","iopub.execute_input":"2021-12-18T05:31:23.790975Z","iopub.status.idle":"2021-12-18T05:32:23.862728Z","shell.execute_reply.started":"2021-12-18T05:31:23.790929Z","shell.execute_reply":"2021-12-18T05:32:23.861657Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# **Import Libraries** ","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport sklearn\nimport torchvision\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport PIL\nimport json\nfrom PIL import Image, ImageEnhance\nimport albumentations as A\nimport mmdet\nimport mmcv\nfrom albumentations.pytorch import ToTensorV2\nimport seaborn as sns\nimport glob\nfrom pathlib import Path\nimport pycocotools\nfrom pycocotools import mask\nimport numpy.random\nimport random\nimport cv2\nimport re\nfrom mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector\nfrom mmdet.apis import inference_detector, init_detector, show_result_pyplot, set_random_seed","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-18T05:36:09.735216Z","iopub.execute_input":"2021-12-18T05:36:09.735561Z","iopub.status.idle":"2021-12-18T05:36:33.537550Z","shell.execute_reply.started":"2021-12-18T05:36:09.735531Z","shell.execute_reply":"2021-12-18T05:36:33.535811Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"%cd ..","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:36:33.541311Z","iopub.execute_input":"2021-12-18T05:36:33.542122Z","iopub.status.idle":"2021-12-18T05:36:33.550153Z","shell.execute_reply.started":"2021-12-18T05:36:33.542075Z","shell.execute_reply":"2021-12-18T05:36:33.549116Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"IMG_WIDTH = 704\nIMG_HEIGHT = 520","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:36:33.552223Z","iopub.execute_input":"2021-12-18T05:36:33.552984Z","iopub.status.idle":"2021-12-18T05:36:33.562986Z","shell.execute_reply.started":"2021-12-18T05:36:33.552939Z","shell.execute_reply":"2021-12-18T05:36:33.561654Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# **Helper Functions**","metadata":{}},{"cell_type":"code","source":"def rle_decode(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\ndef flatten_l_o_l(nested_list):\n    \"\"\" Flatten a list of lists \"\"\"\n    return [item for sublist in nested_list for item in sublist]\n\n\ndef load_json_to_dict(json_path):\n    \"\"\" tbd \"\"\"\n    with open(json_path) as json_file:\n        data = json.load(json_file)\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:36:33.567053Z","iopub.execute_input":"2021-12-18T05:36:33.568029Z","iopub.status.idle":"2021-12-18T05:36:33.584465Z","shell.execute_reply.started":"2021-12-18T05:36:33.567901Z","shell.execute_reply":"2021-12-18T05:36:33.583317Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def get_img_and_mask(img_path, annotation, width, height):\n    \"\"\" Capture the relevant image array as well as the image mask \"\"\"\n    img_mask = np.zeros((height, width), dtype=np.uint8)\n    for i, annot in enumerate(annotation): \n        img_mask = np.where(rle_decode(annot, (height, width))!=0, i, img_mask)\n    img = cv2.imread(img_path)[..., ::-1]\n    return img[..., 0], img_mask\n\ndef plot_img_and_mask(img, mask, invert_img=True, boost_contrast=True):\n    \"\"\" Function to take an image and the corresponding mask and plot\n    \n    Args:\n        img (np.arr): 1 channel np arr representing the image of cellular structures\n        mask (np.arr): 1 channel np arr representing the instance masks (incrementing by one)\n        invert_img (bool, optional): Whether or not to invert the base image\n        boost_contrast (bool, optional): Whether or not to boost contrast of the base image\n        \n    Returns:\n        None; Plots the two arrays and overlays them to create a merged image\n    \"\"\"\n    plt.figure(figsize=(20,10))\n    \n    plt.subplot(1,3,1)\n    _img = np.tile(np.expand_dims(img, axis=-1), 3)\n    \n    # Flip black-->white ... white-->black\n    if invert_img:\n        _img = _img.max()-_img\n        \n    if boost_contrast:\n        _img = np.asarray(ImageEnhance.Contrast(Image.fromarray(_img)).enhance(16))\n        \n    plt.imshow(_img)\n    plt.axis(False)\n    plt.title(\"Cell Image\", fontweight=\"bold\")\n    \n    plt.subplot(1,3,2)\n    _mask = np.zeros_like(_img)\n    _mask[..., 0] = mask\n    plt.imshow(mask, cmap='rainbow')\n    plt.axis(False)\n    plt.title(\"Instance Segmentation Mask\", fontweight=\"bold\")\n    \n    merged = cv2.addWeighted(_img, 0.75, np.clip(_mask, 0, 1)*255, 0.25, 0.0,)\n    plt.subplot(1,3,3)\n    plt.imshow(merged)\n    plt.axis(False)\n    plt.title(\"Cell Image w/ Instance Segmentation Mask Overlay\", fontweight=\"bold\")\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:36:33.586801Z","iopub.execute_input":"2021-12-18T05:36:33.587161Z","iopub.status.idle":"2021-12-18T05:36:33.605424Z","shell.execute_reply.started":"2021-12-18T05:36:33.587120Z","shell.execute_reply":"2021-12-18T05:36:33.604183Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def polygonFromMask(maskedArr, idx):\n    \n  # adapted from https://github.com/hazirbas/coco-json-converter/blob/master/generate_coco_json.py\n    contours, _ = cv2.findContours(maskedArr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    segmentation = []\n    valid_poly = 0\n    for contour in contours:\n  #   Valid polygons have >= 6 coordinates (3 points)\n       if contour.size >= 6:\n        \n        segmentation.append(contour.astype(float).flatten().tolist())\n        valid_poly += 1\n    if valid_poly == 0:\n        raise ValueError(idx)\n    return [segmentation]","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:36:33.607645Z","iopub.execute_input":"2021-12-18T05:36:33.608087Z","iopub.status.idle":"2021-12-18T05:36:33.621440Z","shell.execute_reply.started":"2021-12-18T05:36:33.608043Z","shell.execute_reply":"2021-12-18T05:36:33.620388Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# **Data Visualizations**","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/sartorius-cell-instance-segmentation/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:36:33.622675Z","iopub.execute_input":"2021-12-18T05:36:33.622983Z","iopub.status.idle":"2021-12-18T05:36:34.211239Z","shell.execute_reply.started":"2021-12-18T05:36:33.622903Z","shell.execute_reply":"2021-12-18T05:36:34.210188Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:36:34.216010Z","iopub.execute_input":"2021-12-18T05:36:34.216263Z","iopub.status.idle":"2021-12-18T05:36:34.248721Z","shell.execute_reply.started":"2021-12-18T05:36:34.216234Z","shell.execute_reply":"2021-12-18T05:36:34.246242Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"lines = []\nfor f in train_df.itertuples():\n    lines.append('/kaggle/input/sartorius-cell-instance-segmentation/train/' + f[1] + '.png')","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:36:34.250350Z","iopub.execute_input":"2021-12-18T05:36:34.250777Z","iopub.status.idle":"2021-12-18T05:36:34.432241Z","shell.execute_reply.started":"2021-12-18T05:36:34.250728Z","shell.execute_reply":"2021-12-18T05:36:34.431208Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"lins = pd.Series(lines, name='img_path')","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:36:34.437901Z","iopub.execute_input":"2021-12-18T05:36:34.438218Z","iopub.status.idle":"2021-12-18T05:36:34.449167Z","shell.execute_reply.started":"2021-12-18T05:36:34.438168Z","shell.execute_reply":"2021-12-18T05:36:34.447783Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_df = pd.concat([train_df, lins], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:36:34.451611Z","iopub.execute_input":"2021-12-18T05:36:34.451974Z","iopub.status.idle":"2021-12-18T05:36:34.478634Z","shell.execute_reply.started":"2021-12-18T05:36:34.451934Z","shell.execute_reply":"2021-12-18T05:36:34.477646Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"tmp_df = train_df.drop_duplicates(subset=[\"id\", \"img_path\"]).reset_index(drop=True)\ntmp_df[\"annotation\"] = train_df.groupby(\"id\")[\"annotation\"].agg(list).reset_index(drop=True)\ntrain_df = tmp_df.copy()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:36:34.479936Z","iopub.execute_input":"2021-12-18T05:36:34.480182Z","iopub.status.idle":"2021-12-18T05:36:34.577759Z","shell.execute_reply.started":"2021-12-18T05:36:34.480151Z","shell.execute_reply":"2021-12-18T05:36:34.576817Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:36:34.580271Z","iopub.execute_input":"2021-12-18T05:36:34.580825Z","iopub.status.idle":"2021-12-18T05:36:34.606854Z","shell.execute_reply.started":"2021-12-18T05:36:34.580756Z","shell.execute_reply":"2021-12-18T05:36:34.605895Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def plot_mask(idx):\n    im, mk = get_img_and_mask(**train_df[[\"img_path\", \"annotation\", \"width\", \"height\"]].iloc[idx].to_dict())\n    print\n    plot_img_and_mask(im, mk)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:36:34.608105Z","iopub.execute_input":"2021-12-18T05:36:34.608357Z","iopub.status.idle":"2021-12-18T05:36:34.615172Z","shell.execute_reply.started":"2021-12-18T05:36:34.608297Z","shell.execute_reply":"2021-12-18T05:36:34.613793Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"plot_mask(0)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:36:34.617789Z","iopub.execute_input":"2021-12-18T05:36:34.618273Z","iopub.status.idle":"2021-12-18T05:36:35.517845Z","shell.execute_reply.started":"2021-12-18T05:36:34.618226Z","shell.execute_reply":"2021-12-18T05:36:35.514391Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"plot_mask(1)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:36:35.519123Z","iopub.execute_input":"2021-12-18T05:36:35.520499Z","iopub.status.idle":"2021-12-18T05:36:36.217277Z","shell.execute_reply.started":"2021-12-18T05:36:35.520458Z","shell.execute_reply":"2021-12-18T05:36:36.216500Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"plot_mask(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:36:36.218638Z","iopub.execute_input":"2021-12-18T05:36:36.219823Z","iopub.status.idle":"2021-12-18T05:36:36.863479Z","shell.execute_reply.started":"2021-12-18T05:36:36.219783Z","shell.execute_reply":"2021-12-18T05:36:36.862401Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_df, val_df = train_test_split(train_df, train_size=0.95, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:36:36.865345Z","iopub.execute_input":"2021-12-18T05:36:36.865729Z","iopub.status.idle":"2021-12-18T05:36:36.875177Z","shell.execute_reply.started":"2021-12-18T05:36:36.865693Z","shell.execute_reply":"2021-12-18T05:36:36.873720Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:36:36.877247Z","iopub.execute_input":"2021-12-18T05:36:36.878034Z","iopub.status.idle":"2021-12-18T05:36:36.883687Z","shell.execute_reply.started":"2021-12-18T05:36:36.877994Z","shell.execute_reply":"2021-12-18T05:36:36.882699Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"%%writefile labels.txt\nshsy5y\ncort\nastro","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:36:36.885782Z","iopub.execute_input":"2021-12-18T05:36:36.886606Z","iopub.status.idle":"2021-12-18T05:36:36.898317Z","shell.execute_reply.started":"2021-12-18T05:36:36.886566Z","shell.execute_reply":"2021-12-18T05:36:36.897361Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# **Model Config**","metadata":{}},{"cell_type":"code","source":"from mmcv import Config\n# cfg = Config.fromfile('/kaggle/working/mmdetection/configs/htc/htc_x101_64x4d_fpn_dconv_c3-c5_mstrain_400_1400_16x1_20e_coco.py')\ncfg = Config.fromfile('/kaggle/working/mmdetection/configs/ms_rcnn/ms_rcnn_x101_32x4d_fpn_1x_coco.py')\ncfg1 = Config.fromfile('/kaggle/working/mmdetection/configs/ms_rcnn/ms_rcnn_x101_32x4d_fpn_1x_coco.py')\n\n# cfg = Config.fromfile('/kaggle/working/mmdetection/configs/cascade_rcnn/cascade_mask_rcnn_r50_fpn_20e_coco.py')","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:16:40.455935Z","iopub.execute_input":"2021-12-18T06:16:40.456239Z","iopub.status.idle":"2021-12-18T06:16:40.514389Z","shell.execute_reply.started":"2021-12-18T06:16:40.456208Z","shell.execute_reply":"2021-12-18T06:16:40.513389Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"print(cfg1.pretty_text)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:17:08.537789Z","iopub.execute_input":"2021-12-18T06:17:08.538705Z","iopub.status.idle":"2021-12-18T06:17:08.951558Z","shell.execute_reply.started":"2021-12-18T06:17:08.538640Z","shell.execute_reply":"2021-12-18T06:17:08.950632Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"!mkdir /kaggle/working/mmdetection/configs/sartorius/","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:39:58.643251Z","iopub.execute_input":"2021-12-18T05:39:58.643878Z","iopub.status.idle":"2021-12-18T05:39:58.791498Z","shell.execute_reply.started":"2021-12-18T05:39:58.643844Z","shell.execute_reply":"2021-12-18T05:39:58.790195Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# %%writefile /kaggle/working/mmdetection/configs/sartorius/mask_rcnn_r50_fpn.py\n\n\ncfg.model = dict(\n    type='MaskScoringRCNN',\n    backbone=dict(\n        type='ResNeXt',\n        depth=101,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch',\n        init_cfg=dict(\n            type='Pretrained', checkpoint='open-mmlab://resnext101_32x4d'),\n        groups=32,\n        base_width=4),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        num_outs=5),\n    rpn_head=dict(\n        type='RPNHead',\n        in_channels=256,\n        feat_channels=256,\n        anchor_generator=dict(\n            type='AnchorGenerator',\n            scales=[8],\n            ratios=[0.5, 1.0, 2.0],\n            strides=[4, 8, 16, 32, 64]),\n        bbox_coder=dict(\n            type='DeltaXYWHBBoxCoder',\n            target_means=[0.0, 0.0, 0.0, 0.0],\n            target_stds=[1.0, 1.0, 1.0, 1.0]),\n        loss_cls=dict(\n            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n    roi_head=dict(\n        type='MaskScoringRoIHead',\n        bbox_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        bbox_head=dict(\n            type='Shared2FCBBoxHead',\n            in_channels=256,\n            fc_out_channels=1024,\n            roi_feat_size=7,\n            num_classes=3,\n            bbox_coder=dict(\n                type='DeltaXYWHBBoxCoder',\n                target_means=[0.0, 0.0, 0.0, 0.0],\n                target_stds=[0.1, 0.1, 0.2, 0.2]),\n            reg_class_agnostic=False,\n            loss_cls=dict(\n                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n        mask_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        mask_head=dict(\n            type='FCNMaskHead',\n            num_convs=4,\n            in_channels=256,\n            conv_out_channels=256,\n            num_classes=3,\n            loss_mask=dict(\n                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0)),\n        mask_iou_head=dict(\n            type='MaskIoUHead',\n            num_convs=4,\n            num_fcs=2,\n            roi_feat_size=14,\n            in_channels=256,\n            conv_out_channels=256,\n            fc_out_channels=1024,\n            num_classes=3)))\n# model training and testing settings\ncfg.train_cfg = dict(\n    rpn=dict(\n        assigner=dict(\n            type='MaxIoUAssigner',\n            pos_iou_thr=0.7,\n            neg_iou_thr=0.3,\n            min_pos_iou=0.3,\n            match_low_quality=True,\n            ignore_iof_thr=-1),\n        sampler=dict(\n            type='RandomSampler',\n            num=256,\n            pos_fraction=0.5,\n            neg_pos_ub=-1,\n            add_gt_as_proposals=False),\n        allowed_border=-1,\n        pos_weight=-1,\n        debug=False),\n    rpn_proposal=dict(\n        nms_across_levels=False,\n        nms_pre=2000,\n        nms_post=1000,\n        max_num=1000,\n        nms_thr=0.7,\n        min_bbox_size=0),\n    rcnn=dict(\n        assigner=dict(\n            type='MaxIoUAssigner',\n            pos_iou_thr=0.5,\n            neg_iou_thr=0.5,\n            min_pos_iou=0.5,\n            match_low_quality=True,\n            ignore_iof_thr=-1),\n        sampler=dict(\n            type='RandomSampler',\n            num=512,\n            pos_fraction=0.25,\n            neg_pos_ub=-1,\n            add_gt_as_proposals=True),\n        mask_size=28,\n        pos_weight=-1,\n        debug=False))\n    \n    \ncfg.test_cfg = dict(\n    rpn=dict(\n        nms_across_levels=False,\n        nms_pre=1000,\n        nms_post=1000,\n        max_num=1000,\n        nms_thr=0.7,\n        min_bbox_size=0),\n    rcnn=dict(\n        score_thr=0.05,\n        nms=dict(type='nms', iou_threshold=0.5),\n        max_per_img=400,\n        mask_thr_binary=0.5))","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:09:30.578101Z","iopub.execute_input":"2021-12-18T06:09:30.578434Z","iopub.status.idle":"2021-12-18T06:09:30.600668Z","shell.execute_reply.started":"2021-12-18T06:09:30.578404Z","shell.execute_reply":"2021-12-18T06:09:30.599694Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# cfg.model.roi_head.mask_head.num_classes","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:04:29.654719Z","iopub.execute_input":"2021-12-18T06:04:29.655488Z","iopub.status.idle":"2021-12-18T06:04:29.662776Z","shell.execute_reply.started":"2021-12-18T06:04:29.655456Z","shell.execute_reply":"2021-12-18T06:04:29.661347Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"!wget https://download.openmmlab.com/mmdetection/v2.0/ms_rcnn/ms_rcnn_x101_32x4d_fpn_1x_coco/ms_rcnn_x101_32x4d_fpn_1x_coco_20200206-81fd1740.pth -P /kaggle/working/mmdetection/configs/sartorius/","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:05:49.701066Z","iopub.execute_input":"2021-12-18T06:05:49.701466Z","iopub.status.idle":"2021-12-18T06:06:34.796014Z","shell.execute_reply.started":"2021-12-18T06:05:49.701436Z","shell.execute_reply":"2021-12-18T06:06:34.794752Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"cfg.dataset_type = 'CocoDataset'\ncfg.classes = '/kaggle/working/labels.txt'\ncfg.data_root = '/kaggle/working'\n\n# for head in cfg.model.roi_head.bbox_head:\n#     head.num_classes = 3\n    \n# for head in cfg.model.roi_head.mask_head:\n#     head.num_classes = 3\n    \n# cfg.model.roi_head.mask_head.semantic_head.num_classes=3\n# cfg.model.roi_head.mask_head.num_classes=3\n\ncfg.data.test.type = 'CocoDataset'\ncfg.data.test.classes = 'labels.txt'\ncfg.data.test.data_root = '/kaggle/working'\ncfg.data.test.ann_file = '../input/k/vexxingbanana/sartorius-coco-dataset-notebook/val_dataset.json'\ncfg.data.test.img_prefix = ''\n\ncfg.data.train.type = 'CocoDataset'\ncfg.data.train.data_root = '/kaggle/working'\ncfg.data.train.ann_file = '../input/k/vexxingbanana/sartorius-coco-dataset-notebook/train_dataset.json'\ncfg.data.train.img_prefix = ''\ncfg.data.train.classes = 'labels.txt'\n\ncfg.data.val.type = 'CocoDataset'\ncfg.data.val.data_root = '/kaggle/working'\ncfg.data.val.ann_file = '../input/k/vexxingbanana/sartorius-coco-dataset-notebook/val_dataset.json'\ncfg.data.val.img_prefix = ''\ncfg.data.val.classes = 'labels.txt'\n\nalbu_train_transforms = [\n    dict(type='ShiftScaleRotate', shift_limit=0.0625,\n         scale_limit=0.15, rotate_limit=15, p=0.4),\n    dict(type='RandomBrightnessContrast', brightness_limit=0.2,\n         contrast_limit=0.2, p=0.5),\n#     dict(type='IAAAffine', shear=(-10.0, 10.0), p=0.4),\n#     dict(type='CLAHE', p=0.5),\n    dict(\n        type=\"OneOf\",\n        transforms=[\n            dict(type=\"GaussianBlur\", p=1.0, blur_limit=7),\n            dict(type=\"MedianBlur\", p=1.0, blur_limit=7),\n        ],\n        p=0.4,\n    ),\n]\n\ncfg.train_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n#     dict(type='Resize', img_scale=[(440, 596), (480, 650), (520, 704), (580, 785), (620, 839)], multiscale_mode='value', keep_ratio=True),\n#     dict(type='Resize', img_scale=[(880, 1192), (960, 130), (1040, 1408), (1160, 1570), (1240, 1678)], multiscale_mode='value', keep_ratio=True),\n    dict(type='Resize', img_scale=[(1333, 800), (1690, 960)]),\n#     dict(type='Resize', img_scale=(1333, 800)),\n    \n    \n\n    dict(type='RandomFlip', flip_ratio=0.5),\n\n    dict(\n        type='Albu',\n        transforms=albu_train_transforms,\n        bbox_params=dict(\n        type='BboxParams',\n        format='pascal_voc',\n        label_fields=['gt_labels'],\n        min_visibility=0.0,\n        filter_lost_elements=True),\n        keymap=dict(img='image', gt_bboxes='bboxes', gt_masks='masks'),\n        update_pad_shape=False,\n        skip_img_without_anno=True),\n    dict(\n        type='Normalize',\n        mean=[128, 128, 128],\n        std=[11.58, 11.58, 11.58],\n        to_rgb=True),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'), \n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_masks', 'gt_labels'])\n]\n\ncfg.val_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n#         img_scale=[(880, 1192), (960, 130), (1040, 1408), (1160, 1570), (1240, 1678)],\n        img_scale = [(1333, 800), (1690, 960)],\n#         img_scale=(1333, 800),\n#         img_scale = (520, 704),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[128, 128, 128],\n                std=[11.58, 11.58, 11.58],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\n\n\ncfg.test_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=[(1333, 800), (1690, 960)],\n#         img_scale=(1333, 800),\n        \n#         img_scale = (520, 704),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[128, 128, 128],\n                std=[11.58, 11.58, 11.58],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\n\ncfg.data.train.pipeline = cfg.train_pipeline\ncfg.data.val.pipeline = cfg.val_pipeline\ncfg.data.test.pipeline = cfg.test_pipeline\n\n\n# cfg.model.test_cfg.rcnn.max_per_img = 300\n\n# cfg.load_from = '../input/htc-checkpoint-resnext101/htc_x101_64x4d_fpn_dconv_c3-c5_mstrain_400_1400_16x1_20e_coco_20200312-946fd751.pth'\ncfg.load_from = '/kaggle/working/mmdetection/configs/sartorius/ms_rcnn_x101_32x4d_fpn_1x_coco_20200206-81fd1740.pth'\n# cfg.load_from = '../input/cascade-mask-rcnn-r50/cascade_mask_rcnn_r50_fpn_20e_coco_bbox_mAP-0.419__segm_mAP-0.365_20200504_174711-4af8e66e.pth'\n\ncfg.work_dir = '/kaggle/working/model_output'\n\ncfg.optimizer.lr = 0.02 / 8\ncfg.lr_config = dict(\n    policy='CosineAnnealing', \n    by_epoch=False,\n    warmup='linear', \n    warmup_iters=125, \n    warmup_ratio=0.001,\n    min_lr=1e-07)\n\ncfg.data.samples_per_gpu = 2\ncfg.data.workers_per_gpu = 2\n\ncfg.evaluation.metric = 'segm'\ncfg.evaluation.interval = 1\n\ncfg.checkpoint_config.interval = 1\ncfg.runner.max_epochs = 12\ncfg.log_config.interval = 144\n\n# cfg.model.rpn_head.anchor_generator.base_sizes = [4, 9, 17, 31, 64]\n# cfg.model.rpn_head.anchor_generator.strides = [4, 8, 16, 32, 64]\n\n\ncfg.seed = 0\nset_random_seed(0, deterministic=False)\ncfg.gpu_ids = range(1)\ncfg.fp16 = dict(loss_scale=512.0)\nmeta = dict()\nmeta['config'] = cfg.pretty_text\n\n\n\nprint(f'Config:\\n{cfg.pretty_text}')","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:09:34.415828Z","iopub.execute_input":"2021-12-18T06:09:34.416097Z","iopub.status.idle":"2021-12-18T06:09:37.639983Z","shell.execute_reply.started":"2021-12-18T06:09:34.416068Z","shell.execute_reply":"2021-12-18T06:09:37.639033Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# dataset_type = 'CocoDataset'\n# data_root = 'data/coco/'\n# img_norm_cfg = dict(\n#     mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n# train_pipeline = [\n#     dict(type='LoadImageFromFile'),\n#     dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n#     dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n#     dict(type='RandomFlip', flip_ratio=0.5),\n#     dict(\n#         type='Normalize',\n#         mean=[123.675, 116.28, 103.53],\n#         std=[58.395, 57.12, 57.375],\n#         to_rgb=True),\n#     dict(type='Pad', size_divisor=32),\n#     dict(type='DefaultFormatBundle'),\n#     dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n# ]\n# test_pipeline = [\n#     dict(type='LoadImageFromFile'),\n#     dict(\n#         type='MultiScaleFlipAug',\n#         img_scale=(1333, 800),\n#         flip=False,\n#         transforms=[\n#             dict(type='Resize', keep_ratio=True),\n#             dict(type='RandomFlip'),\n#             dict(\n#                 type='Normalize',\n#                 mean=[123.675, 116.28, 103.53],\n#                 std=[58.395, 57.12, 57.375],\n#                 to_rgb=True),\n#             dict(type='Pad', size_divisor=32),\n#             dict(type='ImageToTensor', keys=['img']),\n#             dict(type='Collect', keys=['img'])\n#         ])\n# ]\n# data = dict(\n#     samples_per_gpu=2,\n#     workers_per_gpu=2,\n#     train=dict(\n#         type='CocoDataset',\n#         ann_file='data/coco/annotations/instances_train2017.json',\n#         img_prefix='data/coco/train2017/',\n#         pipeline=[\n#             dict(type='LoadImageFromFile'),\n#             dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n#             dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n#             dict(type='RandomFlip', flip_ratio=0.5),\n#             dict(\n#                 type='Normalize',\n#                 mean=[123.675, 116.28, 103.53],\n#                 std=[58.395, 57.12, 57.375],\n#                 to_rgb=True),\n#             dict(type='Pad', size_divisor=32),\n#             dict(type='DefaultFormatBundle'),\n#             dict(\n#                 type='Collect',\n#                 keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n#         ]),\n#     val=dict(\n#         type='CocoDataset',\n#         ann_file='data/coco/annotations/instances_val2017.json',\n#         img_prefix='data/coco/val2017/',\n#         pipeline=[\n#             dict(type='LoadImageFromFile'),\n#             dict(\n#                 type='MultiScaleFlipAug',\n#                 img_scale=(1333, 800),\n#                 flip=False,\n#                 transforms=[\n#                     dict(type='Resize', keep_ratio=True),\n#                     dict(type='RandomFlip'),\n#                     dict(\n#                         type='Normalize',\n#                         mean=[123.675, 116.28, 103.53],\n#                         std=[58.395, 57.12, 57.375],\n#                         to_rgb=True),\n#                     dict(type='Pad', size_divisor=32),\n#                     dict(type='ImageToTensor', keys=['img']),\n#                     dict(type='Collect', keys=['img'])\n#                 ])\n#         ]),\n#     test=dict(\n#         type='CocoDataset',\n#         ann_file='data/coco/annotations/instances_val2017.json',\n#         img_prefix='data/coco/val2017/',\n#         pipeline=[\n#             dict(type='LoadImageFromFile'),\n#             dict(\n#                 type='MultiScaleFlipAug',\n#                 img_scale=(1333, 800),\n#                 flip=False,\n#                 transforms=[\n#                     dict(type='Resize', keep_ratio=True),\n#                     dict(type='RandomFlip'),\n#                     dict(\n#                         type='Normalize',\n#                         mean=[123.675, 116.28, 103.53],\n#                         std=[58.395, 57.12, 57.375],\n#                         to_rgb=True),\n#                     dict(type='Pad', size_divisor=32),\n#                     dict(type='ImageToTensor', keys=['img']),\n#                     dict(type='Collect', keys=['img'])\n#                 ])\n#         ]))\n# evaluation = dict(metric=['bbox', 'segm'])\n# optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n# optimizer_config = dict(grad_clip=None)\n# lr_config = dict(\n#     policy='step',\n#     warmup='linear',\n#     warmup_iters=500,\n#     warmup_ratio=0.001,\n#     step=[8, 11])\n# runner = dict(type='EpochBasedRunner', max_epochs=12)\n# checkpoint_config = dict(interval=1)\n# log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n# custom_hooks = [dict(type='NumClassCheckHook')]\n# dist_params = dict(backend='nccl')\n# log_level = 'INFO'\n# load_from = None\n# resume_from = None\n# workflow = [('train', 1)]","metadata":{"execution":{"iopub.status.busy":"2021-12-18T05:58:17.553044Z","iopub.execute_input":"2021-12-18T05:58:17.553338Z","iopub.status.idle":"2021-12-18T05:58:17.601556Z","shell.execute_reply.started":"2021-12-18T05:58:17.553295Z","shell.execute_reply":"2021-12-18T05:58:17.599519Z"},"jupyter":{"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# print(cfg.pretty_text)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T05:25:35.123701Z","iopub.execute_input":"2021-12-17T05:25:35.123937Z","iopub.status.idle":"2021-12-17T05:25:35.651467Z","shell.execute_reply.started":"2021-12-17T05:25:35.123904Z","shell.execute_reply":"2021-12-17T05:25:35.650725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !mkdir /kaggle/working/mmdetection/configs/sartorius/","metadata":{"execution":{"iopub.status.busy":"2021-12-16T22:12:49.10725Z","iopub.execute_input":"2021-12-16T22:12:49.108066Z","iopub.status.idle":"2021-12-16T22:12:49.248076Z","shell.execute_reply.started":"2021-12-16T22:12:49.108032Z","shell.execute_reply":"2021-12-16T22:12:49.246829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-12-16T22:12:53.960243Z","iopub.execute_input":"2021-12-16T22:12:53.961073Z","iopub.status.idle":"2021-12-16T22:13:33.727921Z","shell.execute_reply.started":"2021-12-16T22:12:53.961038Z","shell.execute_reply":"2021-12-16T22:13:33.726774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg.dataset_type = 'CocoDataset'\ncfg.classes = '/kaggle/working/labels.txt'\ncfg.data_root = '/kaggle/working'\n\n# for head in cfg.model.roi_head.bbox_head:\n#     head.num_classes = 3\n    \n# for head in cfg.model.roi_head.mask_head:\n#     head.num_classes = 3\n    \n# cfg.model.roi_head.mask_head.semantic_head.num_classes=3\ncfg.model.roi_head.mask_head.num_classes=3\n\ncfg.data.test.type = 'CocoDataset'\ncfg.data.test.classes = 'labels.txt'\ncfg.data.test.data_root = '/kaggle/working'\ncfg.data.test.ann_file = '../input/k/vexxingbanana/sartorius-coco-dataset-notebook/val_dataset.json'\ncfg.data.test.img_prefix = ''\n\ncfg.data.train.type = 'CocoDataset'\ncfg.data.train.data_root = '/kaggle/working'\ncfg.data.train.ann_file = '../input/k/vexxingbanana/sartorius-coco-dataset-notebook/train_dataset.json'\ncfg.data.train.img_prefix = ''\ncfg.data.train.classes = 'labels.txt'\n\ncfg.data.val.type = 'CocoDataset'\ncfg.data.val.data_root = '/kaggle/working'\ncfg.data.val.ann_file = '../input/k/vexxingbanana/sartorius-coco-dataset-notebook/val_dataset.json'\ncfg.data.val.img_prefix = ''\ncfg.data.val.classes = 'labels.txt'\n\nalbu_train_transforms = [\n    dict(type='ShiftScaleRotate', shift_limit=0.0625,\n         scale_limit=0.15, rotate_limit=15, p=0.4),\n    dict(type='RandomBrightnessContrast', brightness_limit=0.2,\n         contrast_limit=0.2, p=0.5),\n#     dict(type='IAAAffine', shear=(-10.0, 10.0), p=0.4),\n#     dict(type='CLAHE', p=0.5),\n    dict(\n        type=\"OneOf\",\n        transforms=[\n            dict(type=\"GaussianBlur\", p=1.0, blur_limit=7),\n            dict(type=\"MedianBlur\", p=1.0, blur_limit=7),\n        ],\n        p=0.4,\n    ),\n]\n\ncfg.train_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n#     dict(type='Resize', img_scale=[(440, 596), (480, 650), (520, 704), (580, 785), (620, 839)], multiscale_mode='value', keep_ratio=True),\n#     dict(type='Resize', img_scale=[(880, 1192), (960, 130), (1040, 1408), (1160, 1570), (1240, 1678)], multiscale_mode='value', keep_ratio=True),\n    dict(type='Resize', img_scale=[(1333, 800), (1690, 960)]),\n#     dict(type='Resize', img_scale=(1333, 800)),\n    \n    \n\n    dict(type='RandomFlip', flip_ratio=0.5),\n\n    dict(\n        type='Albu',\n        transforms=albu_train_transforms,\n        bbox_params=dict(\n        type='BboxParams',\n        format='pascal_voc',\n        label_fields=['gt_labels'],\n        min_visibility=0.0,\n        filter_lost_elements=True),\n        keymap=dict(img='image', gt_bboxes='bboxes', gt_masks='masks'),\n        update_pad_shape=False,\n        skip_img_without_anno=True),\n    dict(\n        type='Normalize',\n        mean=[128, 128, 128],\n        std=[11.58, 11.58, 11.58],\n        to_rgb=True),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'), \n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_masks', 'gt_labels'])\n]\n\ncfg.val_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n#         img_scale=[(880, 1192), (960, 130), (1040, 1408), (1160, 1570), (1240, 1678)],\n        img_scale = [(1333, 800), (1690, 960)],\n#         img_scale=(1333, 800),\n#         img_scale = (520, 704),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[128, 128, 128],\n                std=[11.58, 11.58, 11.58],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\n\n\ncfg.test_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=[(1333, 800), (1690, 960)],\n#         img_scale=(1333, 800),\n        \n#         img_scale = (520, 704),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[128, 128, 128],\n                std=[11.58, 11.58, 11.58],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\n\ncfg.data.train.pipeline = cfg.train_pipeline\ncfg.data.val.pipeline = cfg.val_pipeline\ncfg.data.test.pipeline = cfg.test_pipeline\n\n\ncfg.model.test_cfg.rcnn.max_per_img = 300\n\n# cfg.load_from = '../input/htc-checkpoint-resnext101/htc_x101_64x4d_fpn_dconv_c3-c5_mstrain_400_1400_16x1_20e_coco_20200312-946fd751.pth'\ncfg.load_from = '/kaggle/working/mmdetection/configs/sartorius/ms_rcnn_x101_32x4d_fpn_1x_coco_20200206-81fd1740.pth'\n# cfg.load_from = '../input/cascade-mask-rcnn-r50/cascade_mask_rcnn_r50_fpn_20e_coco_bbox_mAP-0.419__segm_mAP-0.365_20200504_174711-4af8e66e.pth'\n\ncfg.work_dir = '/kaggle/working/model_output'\n\ncfg.optimizer.lr = 0.02 / 8\ncfg.lr_config = dict(\n    policy='CosineAnnealing', \n    by_epoch=False,\n    warmup='linear', \n    warmup_iters=125, \n    warmup_ratio=0.001,\n    min_lr=1e-07)\n\ncfg.data.samples_per_gpu = 2\ncfg.data.workers_per_gpu = 2\n\ncfg.evaluation.metric = 'segm'\ncfg.evaluation.interval = 1\n\ncfg.checkpoint_config.interval = 1\ncfg.runner.max_epochs = 12\ncfg.log_config.interval = 144\n\n# cfg.model.rpn_head.anchor_generator.base_sizes = [4, 9, 17, 31, 64]\n# cfg.model.rpn_head.anchor_generator.strides = [4, 8, 16, 32, 64]\n\n\ncfg.seed = 0\nset_random_seed(0, deterministic=False)\ncfg.gpu_ids = range(1)\ncfg.fp16 = dict(loss_scale=512.0)\nmeta = dict()\nmeta['config'] = cfg.pretty_text\n\n\n\nprint(f'Config:\\n{cfg.pretty_text}')","metadata":{"execution":{"iopub.status.busy":"2021-12-16T22:15:34.94962Z","iopub.execute_input":"2021-12-16T22:15:34.949963Z","iopub.status.idle":"2021-12-16T22:15:38.32448Z","shell.execute_reply.started":"2021-12-16T22:15:34.949931Z","shell.execute_reply":"2021-12-16T22:15:38.323484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training**","metadata":{}},{"cell_type":"code","source":"datasets = [build_dataset(cfg.data.train)]\nmodel = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\nmodel.CLASSES = datasets[0].CLASSES\n\nmmcv.mkdir_or_exist(os.path.abspath(cfg.work_dir))\ntrain_detector(model, datasets, cfg, distributed=False, validate=True, meta=meta)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T06:10:12.185962Z","iopub.execute_input":"2021-12-18T06:10:12.186252Z","iopub.status.idle":"2021-12-18T06:10:41.058785Z","shell.execute_reply.started":"2021-12-18T06:10:12.186224Z","shell.execute_reply":"2021-12-18T06:10:41.057163Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"cfg.load_from = '/kaggle/working/model_output/epoch_9.pth'\ncfg.work_dir = '/kaggle/working/finetune_output'\ncfg.optimizer.lr = 0.02 / 32\ncfg.lr_config = dict(\n    policy='CosineAnnealing', \n    by_epoch=False,\n    warmup='linear', \n    warmup_iters=1, \n    warmup_ratio=0.001,\n    min_lr=1e-09)\ncfg.runner.max_epochs = 6\n\nmodel = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\nmodel.CLASSES = datasets[0].CLASSES\n\nmmcv.mkdir_or_exist(os.path.abspath(cfg.work_dir))\ntrain_detector(model, datasets, cfg, distributed=False, validate=True, meta=meta)","metadata":{},"execution_count":null,"outputs":[]}]}