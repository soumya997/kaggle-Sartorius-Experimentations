{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92a3adf4",
   "metadata": {
    "papermill": {
     "duration": 0.067058,
     "end_time": "2021-11-22T14:07:17.345115",
     "exception": false,
     "start_time": "2021-11-22T14:07:17.278057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### validation or kfold is not added and also data augmentation is not added yet. Mainly the Ensemble is not performed. Due for tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea49f2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T14:07:17.486283Z",
     "iopub.status.busy": "2021-11-22T14:07:17.485223Z",
     "iopub.status.idle": "2021-11-22T14:07:56.418675Z",
     "shell.execute_reply": "2021-11-22T14:07:56.420142Z",
     "shell.execute_reply.started": "2021-11-22T13:39:17.164975Z"
    },
    "papermill": {
     "duration": 39.012511,
     "end_time": "2021-11-22T14:07:56.420717",
     "exception": false,
     "start_time": "2021-11-22T14:07:17.408206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install ../input/segmentation-models-wheels/efficientnet_pytorch-0.6.3-py3-none-any.whl\n",
    "!pip install ../input/segmentation-models-wheels/pretrainedmodels-0.7.4-py3-none-any.whl\n",
    "!pip install ../input/segmentation-models-wheels/timm-0.3.2-py3-none-any.whl\n",
    "!pip install ../input/segmentation-models-wheels/segmentation_models_pytorch-0.1.3-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e526f0ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T14:07:56.567705Z",
     "iopub.status.busy": "2021-11-22T14:07:56.566398Z",
     "iopub.status.idle": "2021-11-22T14:08:06.332318Z",
     "shell.execute_reply": "2021-11-22T14:08:06.331704Z",
     "shell.execute_reply.started": "2021-11-22T13:39:48.961414Z"
    },
    "papermill": {
     "duration": 9.834399,
     "end_time": "2021-11-22T14:08:06.332561",
     "exception": false,
     "start_time": "2021-11-22T14:07:56.498162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install colorama -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83db0407",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T14:08:06.516860Z",
     "iopub.status.busy": "2021-11-22T14:08:06.515811Z",
     "iopub.status.idle": "2021-11-22T14:08:12.955166Z",
     "shell.execute_reply": "2021-11-22T14:08:12.956060Z",
     "shell.execute_reply.started": "2021-11-22T13:39:56.330540Z"
    },
    "papermill": {
     "duration": 6.559851,
     "end_time": "2021-11-22T14:08:12.956297",
     "exception": false,
     "start_time": "2021-11-22T14:08:06.396446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use your W&B account,\n",
      "Go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as WANDB. \n",
      "Get your W&B access token from here: https://wandb.ai/authorize\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    api_key = user_secrets.get_secret(\"WANDB\")\n",
    "    wandb.login(key=api_key)\n",
    "    anonymous = None\n",
    "except:\n",
    "    anonymous = \"must\"\n",
    "    print('To use your W&B account,\\nGo to Add-ons -> Secrets and provide your W&B access token. Use the Label name as WANDB. \\nGet your W&B access token from here: https://wandb.ai/authorize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1877061",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T14:08:13.131931Z",
     "iopub.status.busy": "2021-11-22T14:08:13.130733Z",
     "iopub.status.idle": "2021-11-22T14:08:16.468686Z",
     "shell.execute_reply": "2021-11-22T14:08:16.467736Z",
     "shell.execute_reply.started": "2021-11-22T13:40:02.012711Z"
    },
    "papermill": {
     "duration": 3.404974,
     "end_time": "2021-11-22T14:08:16.468982",
     "exception": true,
     "start_time": "2021-11-22T14:08:13.064008",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 805, in init\n",
      "    wi.setup(kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 171, in setup\n",
      "    _silent=(settings._quiet or settings._silent) is True,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_login.py\", line 274, in _login\n",
      "    wlogin.prompt_api_key()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_login.py\", line 202, in prompt_api_key\n",
      "    key, status = self._prompt_api_key()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_login.py\", line 185, in _prompt_api_key\n",
      "    no_create=self._settings.force if self._settings else None,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/lib/apikey.py\", line 121, in prompt_api_key\n",
      "    key = input_callback(api_ask).strip()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 978, in getpass\n",
      "    \"getpass was called, but this frontend does not support input requests.\"\n",
      "IPython.core.error.StdinNotImplementedError: getpass was called, but this frontend does not support input requests.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Abnormal program exit\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "problem",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStdinNotImplementedError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0mwi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WandbInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m         \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0m_disable_warning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0m_silent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_quiet\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_silent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36m_login\u001b[0;34m(anonymous, key, relogin, host, force, timeout, _backend, _silent, _disable_warning)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mwlogin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36mprompt_api_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprompt_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prompt_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mApiKeyStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTTY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36m_prompt_api_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0mno_offline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mno_create\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/lib/apikey.py\u001b[0m in \u001b[0;36mprompt_api_key\u001b[0;34m(settings, api, input_callback, browser_callback, no_offline, no_create, local)\u001b[0m\n\u001b[1;32m    120\u001b[0m             )\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_ask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mwrite_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    977\u001b[0m             raise StdinNotImplementedError(\n\u001b[0;32m--> 978\u001b[0;31m                 \u001b[0;34m\"getpass was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m             )\n",
      "\u001b[0;31mStdinNotImplementedError\u001b[0m: getpass was called, but this frontend does not support input requests.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25/363806290.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"kaggle_sartorius_unet_ensemble\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"somusan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexcept_exit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"problem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_seen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: problem"
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"kaggle_sartorius_unet_ensemble\", entity=\"somusan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f45286",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-22T13:40:30.478102Z",
     "iopub.status.busy": "2021-11-22T13:40:30.477529Z",
     "iopub.status.idle": "2021-11-22T13:40:33.835368Z",
     "shell.execute_reply": "2021-11-22T13:40:33.834621Z",
     "shell.execute_reply.started": "2021-11-22T13:40:30.478064Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pdb\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset, sampler\n",
    "from matplotlib import pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def fix_all_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "fix_all_seeds(2021)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84264dd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:40:33.838301Z",
     "iopub.status.busy": "2021-11-22T13:40:33.837867Z",
     "iopub.status.idle": "2021-11-22T13:40:33.885505Z",
     "shell.execute_reply": "2021-11-22T13:40:33.884808Z",
     "shell.execute_reply.started": "2021-11-22T13:40:33.838261Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    seed          = 101\n",
    "    debug         = False # set debug=False for Full Training\n",
    "    exp_name      = 'Unet-effnetb2-512x512-aug2'\n",
    "    model_name    = 'Unet'\n",
    "    backbone0     = 'efficientnet-b2'\n",
    "    backbone1     = 'efficientnet-b7'\n",
    "    backbone2     = 'efficientnet-b6'\n",
    "    backbone3     = 'efficientnet-b5'\n",
    "    batch_size    = 8\n",
    "    train_bs      = 24\n",
    "    valid_bs      = 48\n",
    "    img_size      = [512, 512]\n",
    "    epochs        = 2\n",
    "    lr            = 5e-3\n",
    "    scheduler     = 'CosineAnnealingLR'\n",
    "    min_lr        = 1e-6\n",
    "    T_max         = int(100*6*1.8)\n",
    "    T_0           = 25\n",
    "    warmup_epochs = 0\n",
    "    wd            = 1e-6\n",
    "    n_accumulate  = 32//train_bs\n",
    "#     n_fold        = 5\n",
    "    num_classes   = 1\n",
    "    DEVICE        = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    competition   = 'sartorius'\n",
    "    _wandb_kernel = 'somusan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65de654b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:40:33.886753Z",
     "iopub.status.busy": "2021-11-22T13:40:33.886499Z",
     "iopub.status.idle": "2021-11-22T13:40:33.907847Z",
     "shell.execute_reply": "2021-11-22T13:40:33.907141Z",
     "shell.execute_reply.started": "2021-11-22T13:40:33.886719Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from colorama import init,Fore,Style\n",
    "\n",
    "class PCOLOR:\n",
    "    init()\n",
    "    # COLORS\n",
    "    green = Fore.GREEN\n",
    "    red = Fore.RED\n",
    "    blue = Fore.BLUE\n",
    "    yellow = Fore.YELLOW\n",
    "    magneta = Fore.MAGENTA\n",
    "    cyan = Fore.CYAN\n",
    "\n",
    "    # BRIGHT COLORS\n",
    "    bgreen = Fore.GREEN + Style.BRIGHT\n",
    "    bred = Fore.RED + Style.BRIGHT\n",
    "    bblue = Fore.BLUE + Style.BRIGHT\n",
    "    byellow = Fore.YELLOW + Style.BRIGHT\n",
    "    bmagneta = Fore.MAGENTA + Style.BRIGHT\n",
    "    bcyan = Fore.CYAN + Style.BRIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a66cce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:40:33.910756Z",
     "iopub.status.busy": "2021-11-22T13:40:33.910053Z",
     "iopub.status.idle": "2021-11-22T13:40:33.916994Z",
     "shell.execute_reply": "2021-11-22T13:40:33.916234Z",
     "shell.execute_reply.started": "2021-11-22T13:40:33.910653Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAMPLE_SUBMISSION  = '../input/sartorius-cell-instance-segmentation/sample_submission.csv'\n",
    "TRAIN_CSV = \"../input/sartorius-cell-instance-segmentation/train.csv\"\n",
    "TRAIN_PATH = \"../input/sartorius-cell-instance-segmentation/train\"\n",
    "TEST_PATH = \"../input/sartorius-cell-instance-segmentation/test\"\n",
    "\n",
    "RESNET_MEAN = (0.485, 0.456, 0.406)\n",
    "RESNET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "# (336, 336)\n",
    "IMAGE_RESIZE = (512,512)\n",
    "\n",
    "LEARNING_RATE = 5e-4\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa87273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:40:36.619804Z",
     "iopub.status.busy": "2021-11-22T13:40:36.619206Z",
     "iopub.status.idle": "2021-11-22T13:40:37.144204Z",
     "shell.execute_reply": "2021-11-22T13:40:37.143445Z",
     "shell.execute_reply.started": "2021-11-22T13:40:36.619764Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f205477",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:40:38.409217Z",
     "iopub.status.busy": "2021-11-22T13:40:38.408947Z",
     "iopub.status.idle": "2021-11-22T13:40:38.614919Z",
     "shell.execute_reply": "2021-11-22T13:40:38.614240Z",
     "shell.execute_reply.started": "2021-11-22T13:40:38.409187Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_img_path = \"../input/sartorius-cell-instance-segmentation/train/\"\n",
    "train_mask_path = \"../input/sartorius-binary-mask-dataset\"\n",
    "\n",
    "train_img = [train_img_path +i for i in sorted(os.listdir(train_img_path))]\n",
    "train_mask = [train_mask_path + '/' +i for i in sorted(os.listdir(train_mask_path))]\n",
    "\n",
    "\n",
    "id_list = []\n",
    "\n",
    "for i in train_img:\n",
    "    id_list.append(i.split(\"/\")[-1].split(\".\")[0])\n",
    "\n",
    "columns_tup = list(zip(id_list,train_img,train_mask))\n",
    "df_prep = pd.DataFrame(columns_tup,columns=[\"id\",'img_path','mask_path'])\n",
    "print(df_prep[\"img_path\"][0])\n",
    "print(df_prep[\"mask_path\"][0])\n",
    "\n",
    "df_prep.head()\n",
    "\n",
    "# plt.imshow(plt.imread(df_prep[\"img_path\"][0]))\n",
    "# plt.imshow(np.load(df_prep[\"mask_path\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a286f861",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:40:39.643817Z",
     "iopub.status.busy": "2021-11-22T13:40:39.643295Z",
     "iopub.status.idle": "2021-11-22T13:40:39.652879Z",
     "shell.execute_reply": "2021-11-22T13:40:39.651926Z",
     "shell.execute_reply.started": "2021-11-22T13:40:39.643778Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape, color=1):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.float32)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo : hi] = color\n",
    "    return img.reshape(shape)\n",
    "\n",
    "\n",
    "def build_masks(df_train, image_id, input_shape):\n",
    "    height, width = input_shape\n",
    "    labels = df_train[df_train[\"id\"] == image_id][\"annotation\"].tolist()\n",
    "    mask = np.zeros((height, width))\n",
    "    for label in labels:\n",
    "        mask += rle_decode(label, shape=(height, width))\n",
    "    mask = mask.clip(0, 1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6922cca0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:40:41.731749Z",
     "iopub.status.busy": "2021-11-22T13:40:41.730888Z",
     "iopub.status.idle": "2021-11-22T13:40:41.742669Z",
     "shell.execute_reply": "2021-11-22T13:40:41.741578Z",
     "shell.execute_reply.started": "2021-11-22T13:40:41.731702Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CellDataset(Dataset):\n",
    "    def __init__(self, df,transforms):\n",
    "        self.df = df\n",
    "        self.base_path = TRAIN_PATH\n",
    "#         self.transforms = Compose([Resize(IMAGE_RESIZE[0], IMAGE_RESIZE[1]), \n",
    "#                                    Normalize(mean=RESNET_MEAN, std=RESNET_STD, p=1), \n",
    "#                                    HorizontalFlip(p=0.5),\n",
    "#                                    VerticalFlip(p=0.5),\n",
    "#                                    ToTensorV2()])\n",
    "        self.transforms = transforms \n",
    "        self.gb = self.df.groupby('id')\n",
    "        self.image_ids = df.id.unique().tolist()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        df = self.gb.get_group(image_id)\n",
    "        annotations = df['annotation'].tolist()\n",
    "        image_path = os.path.join(self.base_path, image_id + \".png\")\n",
    "        \n",
    "#         image = Image.open(image_path)\n",
    "        # print(\"image\",image.size)\n",
    "        \n",
    "        image = cv2.imread(image_path,cv2.IMREAD_COLOR)\n",
    "#         print(\"before reshape\",image.shape)\n",
    "#         image = np.reshape(image,(3,512,512))\n",
    "#         image = image.resize((512,512))\n",
    "#         print(\"after reshape\",image.shape)\n",
    "        mask = build_masks(df_train, image_id, input_shape=(520, 704))\n",
    "        mask = (mask >= 1).astype('float32')\n",
    "        augmented = self.transforms(image=image, mask=mask)\n",
    "        image = augmented['image'] #.type(torch.LongTensor)\n",
    "#         print(\"aug shape\",image.shape)\n",
    "        mask = augmented['mask'] # .type(torch.LongTensor)\n",
    "#         print(mask.shape)\n",
    "#         print(image.resize((3,512,512)).shape)\n",
    "        image = np.reshape(image.numpy(),(3, 512, 512))\n",
    "        image = torch.from_numpy(image)\n",
    "#         print(\"img aug type-->\",type(image))\n",
    "#         print(\"after aug -->\", image.shape)\n",
    "#         print(\"mask after aug -->\", mask.reshape((1, IMAGE_RESIZE[0], IMAGE_RESIZE[1])).shape)\n",
    "        return image, mask.reshape((1, IMAGE_RESIZE[0], IMAGE_RESIZE[1]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f8248",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:40:43.240548Z",
     "iopub.status.busy": "2021-11-22T13:40:43.240281Z",
     "iopub.status.idle": "2021-11-22T13:40:43.249066Z",
     "shell.execute_reply": "2021-11-22T13:40:43.247739Z",
     "shell.execute_reply.started": "2021-11-22T13:40:43.240520Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "        A.Resize(*config.img_size),\n",
    "        A.CLAHE(p=0.35),\n",
    "        A.ColorJitter(p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=90, p=0.5),\n",
    "        A.OneOf([\n",
    "            A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n",
    "            A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n",
    "        ], p=0.25),\n",
    "        A.CoarseDropout(max_holes=8, max_height=config.img_size[0]//20, max_width=config.img_size[1]//20,\n",
    "                         min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n",
    "        ToTensorV2()], p=1.0)\n",
    "\n",
    "valid_transform =  A.Compose([\n",
    "        A.Resize(*config.img_size),\n",
    "        ToTensorV2()], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a895e3e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:40:44.623826Z",
     "iopub.status.busy": "2021-11-22T13:40:44.622975Z",
     "iopub.status.idle": "2021-11-22T13:40:44.627660Z",
     "shell.execute_reply": "2021-11-22T13:40:44.626809Z",
     "shell.execute_reply.started": "2021-11-22T13:40:44.623773Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ../input/sartorius-cell-instance-segmentation/train/0030fd0e6378.png\n",
    "# # ../input/sartorius-binary-mask-dataset/0030fd0e6378.npy\n",
    "# # img = cv2.imread(\"../input/sartorius-cell-instance-segmentation/train/0030fd0e6378.png\")\n",
    "# # # img = cv2.resize(img,(512,512,3))\n",
    "# # # img = np.reshape(img,(512,512,3))\n",
    "# # img = img.resize((IMAGE_RESIZE[0], IMAGE_RESIZE[1]))\n",
    "# # print(img)\n",
    "# from PIL import Image\n",
    "# image = Image.open('./image_name.jpg')\n",
    "# # print(\"image\",image.size)\n",
    "# new_image = image.resize((512,512))\n",
    "# # new_image.size\n",
    "# new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a2bc2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:40:45.910124Z",
     "iopub.status.busy": "2021-11-22T13:40:45.909543Z",
     "iopub.status.idle": "2021-11-22T13:40:45.915427Z",
     "shell.execute_reply": "2021-11-22T13:40:45.912977Z",
     "shell.execute_reply.started": "2021-11-22T13:40:45.910087Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import requests\n",
    "# image_url = \"https://media.geeksforgeeks.org/wp-content/uploads/20190715202808/ybear3-300x224.jpg\"\n",
    "# img_data = requests.get(image_url).content\n",
    "# with open('image_name.jpg', 'wb') as handler:\n",
    "#     handler.write(img_data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875c688",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:40:47.805791Z",
     "iopub.status.busy": "2021-11-22T13:40:47.805158Z",
     "iopub.status.idle": "2021-11-22T13:40:48.082229Z",
     "shell.execute_reply": "2021-11-22T13:40:48.081398Z",
     "shell.execute_reply.started": "2021-11-22T13:40:47.805750Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, valid_data = train_test_split(df_train,test_size = 0.2,random_state=42)\n",
    "\n",
    "\n",
    "ds_train = CellDataset(train_data,train_transform)\n",
    "ds_valid = CellDataset(valid_data,valid_transform)\n",
    "\n",
    "image, mask = ds_valid[1]\n",
    "# image.shape, mask.shape\n",
    "# ds_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81466cd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:40:48.338762Z",
     "iopub.status.busy": "2021-11-22T13:40:48.337443Z",
     "iopub.status.idle": "2021-11-22T13:40:48.342484Z",
     "shell.execute_reply": "2021-11-22T13:40:48.341595Z",
     "shell.execute_reply.started": "2021-11-22T13:40:48.338711Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ds_train = ds_train.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d74b87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:40:49.418724Z",
     "iopub.status.busy": "2021-11-22T13:40:49.416462Z",
     "iopub.status.idle": "2021-11-22T13:40:49.431468Z",
     "shell.execute_reply": "2021-11-22T13:40:49.430426Z",
     "shell.execute_reply.started": "2021-11-22T13:40:49.418677Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Creating our dataset\n",
    "# train_dataset = SkinCancerDataset(csv_file=data_csv_file, root_dir=data_dir, transform=data_transforms['train'])\n",
    "# print(len(train_dataset))\n",
    "\n",
    "# train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [4000, 1000])\n",
    "\n",
    "# Dataloader iterators, make sure to shuffle\n",
    "train_dataloader = DataLoader(ds_train, batch_size=config.batch_size, shuffle=False,num_workers=4, pin_memory=True)\n",
    "val_dataloader = DataLoader(ds_valid, batch_size=config.batch_size, shuffle=False,num_workers=4, pin_memory=True)\n",
    "\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {'train': train_dataloader, 'val': val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc80fbed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:40:50.363295Z",
     "iopub.status.busy": "2021-11-22T13:40:50.362850Z",
     "iopub.status.idle": "2021-11-22T13:41:03.357029Z",
     "shell.execute_reply": "2021-11-22T13:41:03.356125Z",
     "shell.execute_reply.started": "2021-11-22T13:40:50.363251Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = next(iter(val_dataloader))\n",
    "images, masks = batch\n",
    "\n",
    "idx=1\n",
    "plt.imshow(images[idx][0], cmap='bone')\n",
    "plt.show()\n",
    "plt.imshow(masks[idx][0], alpha=0.3)\n",
    "plt.show()\n",
    "plt.imshow(images[idx][0], cmap='bone')\n",
    "plt.imshow(masks[idx][0], alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44a8a09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:41:03.360879Z",
     "iopub.status.busy": "2021-11-22T13:41:03.360483Z",
     "iopub.status.idle": "2021-11-22T13:41:03.373456Z",
     "shell.execute_reply": "2021-11-22T13:41:03.372503Z",
     "shell.execute_reply.started": "2021-11-22T13:41:03.360847Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dice_loss(input, target):\n",
    "    input = torch.sigmoid(input)\n",
    "    smooth = 1.0\n",
    "    iflat = input.view(-1)\n",
    "    tflat = target.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    return ((2.0 * intersection + smooth) / (iflat.sum() + tflat.sum() + smooth))\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "class MixedLoss(nn.Module):\n",
    "    def __init__(self, alpha, gamma):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.focal = FocalLoss(gamma)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        loss = self.alpha*self.focal(input, target) - torch.log(dice_loss(input, target))\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d2c689",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:41:03.375492Z",
     "iopub.status.busy": "2021-11-22T13:41:03.375131Z",
     "iopub.status.idle": "2021-11-22T13:41:04.580371Z",
     "shell.execute_reply": "2021-11-22T13:41:04.579637Z",
     "shell.execute_reply.started": "2021-11-22T13:41:03.375459Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !mkdir -p /root/.cache/torch/hub/checkpoints/\n",
    "# !cp ../input/pytorch-pretrained-image-models/resnet34.pth /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n",
    "\n",
    "import torch\n",
    "import collections.abc as container_abcs\n",
    "torch._six.container_abcs = container_abcs\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac94fe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:41:04.582865Z",
     "iopub.status.busy": "2021-11-22T13:41:04.582597Z",
     "iopub.status.idle": "2021-11-22T13:41:22.418932Z",
     "shell.execute_reply": "2021-11-22T13:41:22.418097Z",
     "shell.execute_reply.started": "2021-11-22T13:41:04.582829Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = smp.Unet(config.backbone0, encoder_weights=\"imagenet\", classes=1,activation=None)\n",
    "model1 = smp.Unet(config.backbone1, encoder_weights=\"imagenet\", classes=1,activation=None)\n",
    "model2 = smp.Unet(config.backbone2, encoder_weights=\"imagenet\", classes=1,activation=None)\n",
    "model3 = smp.Unet(config.backbone3, encoder_weights=\"imagenet\", classes=1,activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af404b8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:41:22.420717Z",
     "iopub.status.busy": "2021-11-22T13:41:22.420077Z",
     "iopub.status.idle": "2021-11-22T13:41:22.424390Z",
     "shell.execute_reply": "2021-11-22T13:41:22.423626Z",
     "shell.execute_reply.started": "2021-11-22T13:41:22.420669Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in val_dataloader:\n",
    "#     print(i.items())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697393ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:41:22.425889Z",
     "iopub.status.busy": "2021-11-22T13:41:22.425425Z",
     "iopub.status.idle": "2021-11-22T13:41:22.434297Z",
     "shell.execute_reply": "2021-11-22T13:41:22.433510Z",
     "shell.execute_reply.started": "2021-11-22T13:41:22.425852Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def valid_one_step(model,data):\n",
    "#     for k,v in data.items():\n",
    "#         data[k] = v.to(config.DEVICE)\n",
    "#     loss = model(**data)\n",
    "#     return loss\n",
    "\n",
    "# def validation_one_epoch(model,data_loader):\n",
    "#     model.eval()\n",
    "#     total_loss = 0\n",
    "#     for batch_index, data in enumerate(data_loader):\n",
    "#         loss = validation_one_step(model,data)\n",
    "#         total_loss += loss\n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d985644b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:41:22.436018Z",
     "iopub.status.busy": "2021-11-22T13:41:22.435739Z",
     "iopub.status.idle": "2021-11-22T13:41:22.447992Z",
     "shell.execute_reply": "2021-11-22T13:41:22.447061Z",
     "shell.execute_reply.started": "2021-11-22T13:41:22.435981Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_loop(model, criterion, eval_loader, device=config.DEVICE):\n",
    "    n_batches = len(val_dataloader)\n",
    "    print(n_batches)\n",
    "    running_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        accuracy, f1_scores = [], []\n",
    "        pbar = tqdm(eval_loader, desc='Iterating over evaluation data')\n",
    "        for imgs, masks in pbar:\n",
    "            # pass to device\n",
    "            imgs = imgs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            # forward\n",
    "            out = model(imgs.float())\n",
    "            loss = criterion(out, masks)\n",
    "            running_loss += loss.item()#*imgs.shape[0]\n",
    "            # calculate predictions using output\n",
    "            predicted = (out > 0.5).float()\n",
    "            predicted = predicted.view(-1).cpu().numpy()\n",
    "            labels = masks.view(-1).cpu().numpy()\n",
    "            accuracy.append(accuracy_score(labels, predicted))\n",
    "            f1_scores.append(f1_score(labels, predicted))\n",
    "    acc = sum(accuracy)/len(accuracy)\n",
    "    f1 = sum(f1_scores)/len(f1_scores)\n",
    "#     running_loss /= len(eval_loader.sampler)\n",
    "    epoch_loss = running_loss / n_batches\n",
    "\n",
    "    return {\n",
    "        'accuracy':acc,\n",
    "        'f1_macro':f1, \n",
    "        'loss':running_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68673558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T13:57:53.452477Z",
     "iopub.status.busy": "2021-11-22T13:57:53.451969Z",
     "iopub.status.idle": "2021-11-22T14:05:18.132131Z",
     "shell.execute_reply": "2021-11-22T14:05:18.130784Z",
     "shell.execute_reply.started": "2021-11-22T13:57:53.452430Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "n_batches = len(train_dataloader)\n",
    "n_batches_val = len(val_dataloader)\n",
    "\n",
    "# model1.cuda()\n",
    "model.to(config.DEVICE)\n",
    "model.train()\n",
    "\n",
    "criterion = MixedLoss(10.0, 2.0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "EPOCHS = config.epochs\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f\"Starting epoch: {epoch} / {EPOCHS}\")\n",
    "    running_loss = 0.0\n",
    "    running_loss_val  = 0.0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    accuracy, f1_scores = [], []\n",
    "    accuracy_val, f1_scores_val = [], []\n",
    "    #     batch_idx = 0\n",
    "    #         batch_idx+=1\n",
    "    for batch in train_dataloader:\n",
    "        \n",
    "        images, masks = batch\n",
    "        images, masks = images.to(config.DEVICE),  masks.to(config.DEVICE)\n",
    "        \n",
    "        outputs = model(images.float())\n",
    "        loss = criterion(outputs, masks)\n",
    "    \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        predicted = predicted.view(-1).cpu().numpy()\n",
    "        labels = masks.view(-1).cpu().numpy()\n",
    "        accuracy.append(accuracy_score(labels, predicted))\n",
    "        f1_scores.append(f1_score(labels, predicted))\n",
    "        \n",
    "    for batch_val in val_dataloader:\n",
    "\n",
    "        \n",
    "        images_val, masks_val = batch_val\n",
    "        images_val, masks_val = images_val.to(config.DEVICE),  masks_val.to(config.DEVICE)\n",
    "        \n",
    "        outputs_val = model(images_val.float())\n",
    "        loss_val = criterion(outputs_val, masks_val)\n",
    "        \n",
    "        \n",
    "        #         loss.backward()\n",
    "        #         optimizer.step()\n",
    "        #         optimizer.zero_grad()\n",
    "        \n",
    "        running_loss_val += loss.item()\n",
    "        predicted = (outputs_val > 0.5).float()\n",
    "        predicted = predicted.view(-1).cpu().numpy()\n",
    "        labels = masks_val.view(-1).cpu().numpy()\n",
    "        accuracy_val.append(accuracy_score(labels, predicted))\n",
    "        f1_scores_val.append(f1_score(labels, predicted))\n",
    "    \n",
    "    #     val_eval = eval_loop(model,criterion,val_dataloader)\n",
    "    #     print(type(val_eval))\n",
    "    #     print(val_eval[\"loss\"])\n",
    "    #     print(val_eval[\"accuracy\"])\n",
    "    #     print(val_eval[\"f1_macro\"])\n",
    "    #     val_loss = val_eval[\"loss\"]\n",
    "    #     val_acc = val_eval[\"accuracy\"]\n",
    "    #     val_f1 = val_eval[\"f1_macro\"]\n",
    "    \n",
    "    val_loss = running_loss_val/ n_batches_val\n",
    "    val_acc = sum(accuracy_val) / len(accuracy_val)\n",
    "    val_f1 = sum(f1_scores_val) / len(f1_scores_val)\n",
    "\n",
    "    epoch_loss = running_loss / n_batches\n",
    "    epoch_acc = sum(accuracy)/len(accuracy)\n",
    "    epoch_f1 = sum(f1_scores)/len(f1_scores)\n",
    "    \n",
    "    print(f\"Epoch: {epoch} - Train Loss {epoch_loss:.4f} - Train acc {epoch_acc:.4f} - Train f1 {epoch_f1:.4f}\")\n",
    "    print(f\"Epoch: {epoch} - Validation Loss {val_loss} - Validation acc {val_acc} - Validation f1 {val_f1}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a05e495",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T14:05:27.949119Z",
     "iopub.status.busy": "2021-11-22T14:05:27.948527Z",
     "iopub.status.idle": "2021-11-22T14:05:28.704591Z",
     "shell.execute_reply": "2021-11-22T14:05:28.703655Z",
     "shell.execute_reply.started": "2021-11-22T14:05:27.949083Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471dbcc2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:44:24.100632Z",
     "iopub.status.idle": "2021-11-22T13:44:24.101508Z",
     "shell.execute_reply": "2021-11-22T13:44:24.101240Z",
     "shell.execute_reply.started": "2021-11-22T13:44:24.101201Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FILE1 = \"./model0_50_val.pth\"\n",
    "# torch.save(model1.state_dict(), FILE1)\n",
    "\n",
    "# wandb.save(\"./model0_50_val.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc87ed",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:44:24.103277Z",
     "iopub.status.idle": "2021-11-22T13:44:24.104283Z",
     "shell.execute_reply": "2021-11-22T13:44:24.103962Z",
     "shell.execute_reply.started": "2021-11-22T13:44:24.103937Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "# n_batches = len(train_dataloader)\n",
    "\n",
    "# # model1.cuda()\n",
    "# model1.to(config.DEVICE)\n",
    "# model1.train()\n",
    "\n",
    "# criterion = MixedLoss(10.0, 2.0)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "\n",
    "# for epoch in range(1, EPOCHS + 1):\n",
    "#     print(f\"Starting epoch: {epoch} / {EPOCHS}\")\n",
    "#     running_loss = 0.0\n",
    "#     optimizer.zero_grad()\n",
    "    \n",
    "#     accuracy, f1_scores = [], []\n",
    "#     for batch_idx, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        \n",
    "#         images, masks = batch\n",
    "#         images, masks = images.to(config.DEVICE),  masks.to(config.DEVICE)\n",
    "        \n",
    "#         outputs = model(images.float())\n",
    "#         loss = criterion(outputs, masks)\n",
    "        \n",
    "        \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "#         running_loss += loss.item()\n",
    "#         predicted = (outputs > 0.5).float()\n",
    "#         predicted = predicted.view(-1).cpu().numpy()\n",
    "#         labels = masks.view(-1).cpu().numpy()\n",
    "#         accuracy.append(accuracy_score(labels, predicted))\n",
    "#         f1_scores.append(f1_score(labels, predicted))\n",
    "    \n",
    "#     val_eval = eval_loop(model1,criterion,val_dataloader)\n",
    "# #     print(type(val_eval))\n",
    "# #     print(val_eval[\"loss\"])\n",
    "# #     print(val_eval[\"accuracy\"])\n",
    "# #     print(val_eval[\"f1_macro\"])\n",
    "#     val_loss = val_eval[\"loss\"]\n",
    "#     val_acc = val_eval[\"accuracy\"]\n",
    "#     val_f1 = val_eval[\"f1_macro\"]\n",
    "\n",
    "#     epoch_loss = running_loss / n_batches\n",
    "#     epoch_acc = sum(accuracy)/len(accuracy)\n",
    "#     epoch_f1 = sum(f1_scores)/len(f1_scores)\n",
    "    \n",
    "#     print(f\"Epoch: {epoch} - Train Loss {epoch_loss:.4f} - Train acc {epoch_acc:.4f} - Train f1 {epoch_f1:.4f}\")\n",
    "#     print(f\"Epoch: {epoch} - Validation Loss {val_loss} - Validation acc {val_acc} - Validation f1 {val_f1}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d26fea",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:44:24.105876Z",
     "iopub.status.idle": "2021-11-22T13:44:24.106401Z",
     "shell.execute_reply": "2021-11-22T13:44:24.106099Z",
     "shell.execute_reply.started": "2021-11-22T13:44:24.106076Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FILE1 = \"./model1_50_val.pth\"\n",
    "# torch.save(model1.state_dict(), FILE1)\n",
    "\n",
    "# wandb.save(\"./model1_50_val.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aa796a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:44:24.107706Z",
     "iopub.status.idle": "2021-11-22T13:44:24.108457Z",
     "shell.execute_reply": "2021-11-22T13:44:24.108167Z",
     "shell.execute_reply.started": "2021-11-22T13:44:24.108141Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "n_batches = len(train_dataloader)\n",
    "\n",
    "# model1.cuda()\n",
    "model2.to(config.DEVICE)\n",
    "model2.train()\n",
    "\n",
    "criterion = MixedLoss(10.0, 2.0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f\"Starting epoch: {epoch} / {EPOCHS}\")\n",
    "    running_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    accuracy, f1_scores = [], []\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        \n",
    "        images, masks = batch\n",
    "        images, masks = images.to(config.DEVICE),  masks.to(config.DEVICE)\n",
    "        \n",
    "        outputs = model(images.float())\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss.item()\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        predicted = predicted.view(-1).cpu().numpy()\n",
    "        labels = masks.view(-1).cpu().numpy()\n",
    "        accuracy.append(accuracy_score(labels, predicted))\n",
    "        f1_scores.append(f1_score(labels, predicted))\n",
    "    \n",
    "    val_eval = eval_loop(model2,criterion,val_dataloader)\n",
    "#     print(type(val_eval))\n",
    "#     print(val_eval[\"loss\"])\n",
    "#     print(val_eval[\"accuracy\"])\n",
    "#     print(val_eval[\"f1_macro\"])\n",
    "    val_loss = val_eval[\"loss\"]\n",
    "    val_acc = val_eval[\"accuracy\"]\n",
    "    val_f1 = val_eval[\"f1_macro\"]\n",
    "\n",
    "    epoch_loss = running_loss / n_batches\n",
    "    epoch_acc = sum(accuracy)/len(accuracy)\n",
    "    epoch_f1 = sum(f1_scores)/len(f1_scores)\n",
    "    \n",
    "    print(f\"Epoch: {epoch} - Train Loss {epoch_loss:.4f} - Train acc {epoch_acc:.4f} - Train f1 {epoch_f1:.4f}\")\n",
    "    print(f\"Epoch: {epoch} - Validation Loss {val_loss} - Validation acc {val_acc} - Validation f1 {val_f1}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7dbd34",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:44:24.110119Z",
     "iopub.status.idle": "2021-11-22T13:44:24.110919Z",
     "shell.execute_reply": "2021-11-22T13:44:24.110582Z",
     "shell.execute_reply.started": "2021-11-22T13:44:24.110543Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FILE1 = \"./model2_50_val.pth\"\n",
    "torch.save(model1.state_dict(), FILE1)\n",
    "\n",
    "wandb.save(\"./model2_50_val.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b8e142",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:44:24.112831Z",
     "iopub.status.idle": "2021-11-22T13:44:24.113376Z",
     "shell.execute_reply": "2021-11-22T13:44:24.113157Z",
     "shell.execute_reply.started": "2021-11-22T13:44:24.113131Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "n_batches = len(train_dataloader)\n",
    "\n",
    "# model1.cuda()\n",
    "model3.to(config.DEVICE)\n",
    "model3.train()\n",
    "\n",
    "criterion = MixedLoss(10.0, 2.0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f\"Starting epoch: {epoch} / {EPOCHS}\")\n",
    "    running_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    accuracy, f1_scores = [], []\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        \n",
    "        images, masks = batch\n",
    "        images, masks = images.to(config.DEVICE),  masks.to(config.DEVICE)\n",
    "        \n",
    "        outputs = model(images.float())\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss.item()\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        predicted = predicted.view(-1).cpu().numpy()\n",
    "        labels = masks.view(-1).cpu().numpy()\n",
    "        accuracy.append(accuracy_score(labels, predicted))\n",
    "        f1_scores.append(f1_score(labels, predicted))\n",
    "    \n",
    "    val_eval = eval_loop(model3,criterion,val_dataloader)\n",
    "#     print(type(val_eval))\n",
    "#     print(val_eval[\"loss\"])\n",
    "#     print(val_eval[\"accuracy\"])\n",
    "#     print(val_eval[\"f1_macro\"])\n",
    "    val_loss = val_eval[\"loss\"]\n",
    "    val_acc = val_eval[\"accuracy\"]\n",
    "    val_f1 = val_eval[\"f1_macro\"]\n",
    "\n",
    "    epoch_loss = running_loss / n_batches\n",
    "    epoch_acc = sum(accuracy)/len(accuracy)\n",
    "    epoch_f1 = sum(f1_scores)/len(f1_scores)\n",
    "    \n",
    "    print(f\"Epoch: {epoch} - Train Loss {epoch_loss:.4f} - Train acc {epoch_acc:.4f} - Train f1 {epoch_f1:.4f}\")\n",
    "    print(f\"Epoch: {epoch} - Validation Loss {val_loss} - Validation acc {val_acc} - Validation f1 {val_f1}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6504767",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.841163Z",
     "iopub.status.idle": "2021-11-22T13:40:25.841740Z",
     "shell.execute_reply": "2021-11-22T13:40:25.841498Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.841472Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FILE1 = \"./model3_50_val.pth\"\n",
    "torch.save(model1.state_dict(), FILE1)\n",
    "\n",
    "wandb.save(\"./model3_50_val.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2ba6b6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.842824Z",
     "iopub.status.idle": "2021-11-22T13:40:25.843396Z",
     "shell.execute_reply": "2021-11-22T13:40:25.843175Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.843149Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class sartorius_dataset():\n",
    "#     def __init__(self,df,transforms):\n",
    "#         self.df = df\n",
    "#         self.img_path = df[\"img_path\"].values()\n",
    "#         self.mask_path = df[\"mask_path\"].values()\n",
    "#         self.transforms = transforms\n",
    "#     def __len__(self):\n",
    "#         return len(self.df)\n",
    "#     def __getitem__(self,idx):\n",
    "#         img_file = self.img_path[idx]\n",
    "#         img = cv2.imread(img_file,cv2.IMREAD_COLOR)\n",
    "#         mask_file = self.mask_path[idx]\n",
    "#         mask = np.load(mask_file)\n",
    "#         data = self.transforms(image = img,mask=mask)\n",
    "#         mask = data[\"mask\"]\n",
    "#         mask = np.expand_dims(mask,axis=0)\n",
    "#         return data[\"image\"], mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a1c43",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.844469Z",
     "iopub.status.idle": "2021-11-22T13:40:25.845034Z",
     "shell.execute_reply": "2021-11-22T13:40:25.844827Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.844800Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class BuildDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, df, transforms=None):\n",
    "#         self.df = df\n",
    "# #         self.img_paths = df[\"img_path\"].values()\n",
    "#         self.img_paths = np.array(df['img_path'])\n",
    "#         try: # if there is no mask then only send images --> test data\n",
    "# #             self.mask_paths = df[\"mask_path\"].values()\n",
    "#             self.msk_paths = np.array(df['mask_path'])\n",
    "\n",
    "#         except:\n",
    "#             self.msk_paths  = None\n",
    "#         self.transforms = transforms\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.df)\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         img_path = self.img_paths[index]\n",
    "#         img      = cv2.imread(img_path,cv2.IMREAD_COLOR)\n",
    "#         if self.msk_paths is not None:\n",
    "#             msk_path = self.msk_paths[index]\n",
    "#             msk      = np.load(msk_path)\n",
    "#             if self.transforms:\n",
    "#                 data = self.transforms(image=img, mask=msk)\n",
    "#                 img  = data['image']\n",
    "#                 msk  = data['mask']\n",
    "#             msk      = np.expand_dims(msk, axis=0) # output_shape: (batch_size, 1, img_size, img_size)\n",
    "#             return img, msk\n",
    "#         else:\n",
    "#             if self.transforms:\n",
    "#                 data = self.transforms(image=img)\n",
    "#                 img  = data['image']\n",
    "#             return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cd50e7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.846110Z",
     "iopub.status.idle": "2021-11-22T13:40:25.846696Z",
     "shell.execute_reply": "2021-11-22T13:40:25.846441Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.846414Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class CellDataset(Dataset):\n",
    "#     def __init__(self, df):\n",
    "#         self.df = df\n",
    "#         self.base_path = TRAIN_PATH\n",
    "#         self.transforms = Compose([Resize(IMAGE_RESIZE[0], IMAGE_RESIZE[1]), \n",
    "#                                    Normalize(mean=RESNET_MEAN, std=RESNET_STD, p=1), \n",
    "#                                    HorizontalFlip(p=0.5),\n",
    "#                                    VerticalFlip(p=0.5),\n",
    "#                                    ToTensorV2()])\n",
    "#         self.gb = self.df.groupby('id')\n",
    "#         self.image_ids = df.id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a764b7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.847789Z",
     "iopub.status.idle": "2021-11-22T13:40:25.848331Z",
     "shell.execute_reply": "2021-11-22T13:40:25.848123Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.848096Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# unique().tolist()\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         image_id = self.image_ids[idx]\n",
    "#         df = self.gb.get_group(image_id)\n",
    "#         annotations = df['annotation'].tolist()\n",
    "#         image_path = os.path.join(self.base_path, image_id + \".png\")\n",
    "#         image = cv2.imread(image_path)\n",
    "#         mask = build_masks(df_train, image_id, input_shape=(520, 704))\n",
    "#         mask = (mask >= 1).astype('float32')\n",
    "#         augmented = self.transforms(image=image, mask=mask)\n",
    "#         image = augmented['image']\n",
    "#         mask = augmented['mask']\n",
    "#         return image, mask.reshape((1, IMAGE_RESIZE[0], IMAGE_RESIZE[1]))\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a48ad3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.849475Z",
     "iopub.status.idle": "2021-11-22T13:40:25.850076Z",
     "shell.execute_reply": "2021-11-22T13:40:25.849855Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.849827Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_transform = A.Compose([\n",
    "#         A.Resize(*config.img_size),\n",
    "#         A.CLAHE(p=0.35),\n",
    "#         A.ColorJitter(p=0.5),\n",
    "#         A.HorizontalFlip(p=0.5),\n",
    "#         A.VerticalFlip(p=0.5),\n",
    "#         A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=90, p=0.5),\n",
    "#         A.OneOf([\n",
    "#             A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n",
    "#             A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n",
    "#         ], p=0.25),\n",
    "#         A.CoarseDropout(max_holes=8, max_height=config.img_size[0]//20, max_width=config.img_size[1]//20,\n",
    "#                          min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n",
    "#         ToTensorV2()], p=1.0)\n",
    "\n",
    "# valid_transform =  A.Compose([\n",
    "#         A.Resize(*config.img_size),\n",
    "#         ToTensorV2()], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f4804",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.851174Z",
     "iopub.status.idle": "2021-11-22T13:40:25.851758Z",
     "shell.execute_reply": "2021-11-22T13:40:25.851505Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.851479Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train_data, valid_data = train_test_split(df_prep,test_size = 0.2,random_state=42)\n",
    "\n",
    "\n",
    "# ds_train = BuildDataset(train_data,train_transform)\n",
    "# ds_valid = BuildDataset(valid_data,valid_transform)\n",
    "\n",
    "# image, mask = ds_valid[1]\n",
    "# image.shape, mask.shape\n",
    "# # ds_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac508da",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.852853Z",
     "iopub.status.idle": "2021-11-22T13:40:25.853400Z",
     "shell.execute_reply": "2021-11-22T13:40:25.853184Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.853159Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# # Creating our dataset\n",
    "# # train_dataset = SkinCancerDataset(csv_file=data_csv_file, root_dir=data_dir, transform=data_transforms['train'])\n",
    "# # print(len(train_dataset))\n",
    "\n",
    "# # train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [4000, 1000])\n",
    "\n",
    "# # Dataloader iterators, make sure to shuffle\n",
    "# train_dataloader = DataLoader(ds_train, batch_size=config.batch_size, shuffle=False,num_workers=4, pin_memory=True)\n",
    "# val_dataloader = DataLoader(ds_valid, batch_size=config.batch_size, shuffle=False,num_workers=4, pin_memory=True)\n",
    "\n",
    "# # Create training and validation dataloaders\n",
    "# dataloaders_dict = {'train': train_dataloader, 'val': val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b97188e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.854450Z",
     "iopub.status.idle": "2021-11-22T13:40:25.855021Z",
     "shell.execute_reply": "2021-11-22T13:40:25.854815Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.854788Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataloaders_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d2bd96",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.856077Z",
     "iopub.status.idle": "2021-11-22T13:40:25.856634Z",
     "shell.execute_reply": "2021-11-22T13:40:25.856407Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.856380Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.imshow(image[0], cmap='bone')\n",
    "# plt.show()\n",
    "# plt.imshow(mask[0], alpha=0.3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8285fe2a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.857825Z",
     "iopub.status.idle": "2021-11-22T13:40:25.858456Z",
     "shell.execute_reply": "2021-11-22T13:40:25.858228Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.858199Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dl_train = DataLoader(ds_train, batch_size=64, num_workers=4, pin_memory=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fcfaa2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.859642Z",
     "iopub.status.idle": "2021-11-22T13:40:25.860234Z",
     "shell.execute_reply": "2021-11-22T13:40:25.859999Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.859971Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91847604",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.861362Z",
     "iopub.status.idle": "2021-11-22T13:40:25.861950Z",
     "shell.execute_reply": "2021-11-22T13:40:25.861729Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.861701Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch = next(iter(val_dataloader))\n",
    "# images, masks = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3b7ae0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.863125Z",
     "iopub.status.idle": "2021-11-22T13:40:25.863800Z",
     "shell.execute_reply": "2021-11-22T13:40:25.863548Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.863503Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# idx=1\n",
    "# plt.imshow(images[idx][0], cmap='bone')\n",
    "# plt.show()\n",
    "# plt.imshow(masks[idx][0], alpha=0.3)\n",
    "# plt.show()\n",
    "# plt.imshow(images[idx][0], cmap='bone')\n",
    "# plt.imshow(masks[idx][0], alpha=0.3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76599a3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.864949Z",
     "iopub.status.idle": "2021-11-22T13:40:25.865545Z",
     "shell.execute_reply": "2021-11-22T13:40:25.865320Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.865293Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def dice_loss(input, target):\n",
    "#     input = torch.sigmoid(input)\n",
    "#     smooth = 1.0\n",
    "#     iflat = input.view(-1)\n",
    "#     tflat = target.view(-1)\n",
    "#     intersection = (iflat * tflat).sum()\n",
    "#     return ((2.0 * intersection + smooth) / (iflat.sum() + tflat.sum() + smooth))\n",
    "\n",
    "\n",
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, gamma):\n",
    "#         super().__init__()\n",
    "#         self.gamma = gamma\n",
    "\n",
    "#     def forward(self, input, target):\n",
    "#         if not (target.size() == input.size()):\n",
    "#             raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "#                              .format(target.size(), input.size()))\n",
    "#         max_val = (-input).clamp(min=0)\n",
    "#         loss = input - input * target + max_val + \\\n",
    "#             ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "#         invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "#         loss = (invprobs * self.gamma).exp() * loss\n",
    "#         return loss.mean()\n",
    "\n",
    "\n",
    "# class MixedLoss(nn.Module):\n",
    "#     def __init__(self, alpha, gamma):\n",
    "#         super().__init__()\n",
    "#         self.alpha = alpha\n",
    "#         self.focal = FocalLoss(gamma)\n",
    "\n",
    "#     def forward(self, input, target):\n",
    "#         loss = self.alpha*self.focal(input, target) - torch.log(dice_loss(input, target))\n",
    "#         return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae80ba",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.866691Z",
     "iopub.status.idle": "2021-11-22T13:40:25.867277Z",
     "shell.execute_reply": "2021-11-22T13:40:25.867047Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.867020Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # !mkdir -p /root/.cache/torch/hub/checkpoints/\n",
    "# # !cp ../input/pytorch-pretrained-image-models/resnet34.pth /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n",
    "\n",
    "# import torch\n",
    "# import collections.abc as container_abcs\n",
    "# torch._six.container_abcs = container_abcs\n",
    "# import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aef05a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2213dd6a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.868484Z",
     "iopub.status.idle": "2021-11-22T13:40:25.869099Z",
     "shell.execute_reply": "2021-11-22T13:40:25.868882Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.868854Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = smp.Unet(config.backbone0, encoder_weights=\"imagenet\", classes=1,activation=None)\n",
    "# model1 = smp.Unet(config.backbone1, encoder_weights=\"imagenet\", classes=1,activation=None)\n",
    "# model2 = smp.Unet(config.backbone2, encoder_weights=\"imagenet\", classes=1,activation=None)\n",
    "# model3 = smp.Unet(config.backbone3, encoder_weights=\"imagenet\", classes=1,activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99e2731",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.870247Z",
     "iopub.status.idle": "2021-11-22T13:40:25.870834Z",
     "shell.execute_reply": "2021-11-22T13:40:25.870614Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.870587Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check model details\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4278d879",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Model0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64cdd4c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.872084Z",
     "iopub.status.idle": "2021-11-22T13:40:25.872740Z",
     "shell.execute_reply": "2021-11-22T13:40:25.872487Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.872458Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# def train_loop(model, optimizer, criterion, train_loader, device=config.DEVICE):\n",
    "#     running_loss = 0\n",
    "#     model.train()\n",
    "#     pbar = tqdm(train_loader, desc='Iterating over train data')\n",
    "#     for imgs, masks in pbar:\n",
    "#         # pass to device\n",
    "#         imgs = imgs.to(device)\n",
    "#         masks = masks.to(device)\n",
    "#         # forward\n",
    "#         out = model(imgs)\n",
    "#         loss = criterion(out, masks)\n",
    "#         running_loss += loss.item()*imgs.shape[0]  # += loss * current batch size\n",
    "#         # optimize\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     running_loss /= len(train_loader.sampler)\n",
    "#     return running_loss\n",
    "\n",
    "\n",
    "# def eval_loop(model, criterion, eval_loader, device=config.DEVICE):\n",
    "#     running_loss = 0\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         accuracy, f1_scores = [], []\n",
    "#         pbar = tqdm(eval_loader, desc='Iterating over evaluation data')\n",
    "#         for imgs, masks in pbar:\n",
    "#             # pass to device\n",
    "#             imgs = imgs.to(device)\n",
    "#             masks = masks.to(device)\n",
    "#             # forward\n",
    "#             out = model(imgs)\n",
    "#             loss = criterion(out, masks)\n",
    "#             running_loss += loss.item()*imgs.shape[0]\n",
    "#             # calculate predictions using output\n",
    "#             predicted = (out > 0.5).float()\n",
    "#             predicted = predicted.view(-1).cpu().numpy()\n",
    "#             labels = masks.view(-1).cpu().numpy()\n",
    "#             accuracy.append(accuracy_score(labels, predicted))\n",
    "#             f1_scores.append(f1_score(labels, predicted))\n",
    "#     acc = sum(accuracy)/len(accuracy)\n",
    "#     f1 = sum(f1_scores)/len(f1_scores)\n",
    "#     running_loss /= len(eval_loader.sampler)\n",
    "#     return {\n",
    "#         'accuracy':acc,\n",
    "#         'f1_macro':f1, \n",
    "#         'loss':running_loss}\n",
    "\n",
    "\n",
    "# def train(model, optimizer, criterion, train_loader, valid_loader,\n",
    "#           device=config.DEVICE, \n",
    "#           num_epochs=30, \n",
    "#           valid_loss_min=np.inf,\n",
    "#           logdir='logdir'):\n",
    "    \n",
    "#     tb_writer = SummaryWriter(log_dir=logdir)\n",
    "#     for e in range(num_epochs):\n",
    "#         # train for epoch\n",
    "#         train_loss = train_loop(\n",
    "#             model, optimizer, criterion, train_loader, device=device)\n",
    "#         # evaluate on validation set\n",
    "#         metrics = eval_loop(\n",
    "#             model, criterion, valid_loader, device=device\n",
    "#         )\n",
    "#         # show progress\n",
    "#         print_string = f'Epoch: {e+1} '\n",
    "#         print_string+= f'TrainLoss: {train_loss:.5f} '\n",
    "#         print_string+= f'ValidLoss: {metrics[\"loss\"]:.5f} '\n",
    "#         print_string+= f'ACC: {metrics[\"accuracy\"]:.5f} '\n",
    "#         print_string+= f'F1: {metrics[\"f1_macro\"]:.3f}'\n",
    "#         print(print_string)\n",
    "\n",
    "#         # Tensorboards Logging\n",
    "#         tb_writer.add_scalar('UNet/Train Loss', train_loss, e)\n",
    "#         tb_writer.add_scalar('UNet/Valid Loss', metrics[\"loss\"], e)\n",
    "#         tb_writer.add_scalar('UNet/Accuracy', metrics[\"accuracy\"], e)\n",
    "#         tb_writer.add_scalar('UNet/F1 Macro', metrics[\"f1_macro\"], e)\n",
    "\n",
    "#         # save the model \n",
    "#         if metrics[\"loss\"] <= valid_loss_min:\n",
    "#             torch.save(model.state_dict(), 'UNet.pt')\n",
    "#             valid_loss_min = metrics[\"loss\"]\n",
    "            \n",
    "            \n",
    "# # set_seed(21)\n",
    "# # model = UNet(3, 1).to(device)\n",
    "# model.to(device=config.DEVICE)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
    "# criterion = MixedLoss(10.0, 2.0)\n",
    "# train(model, optimizer, criterion, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d50827",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.873963Z",
     "iopub.status.idle": "2021-11-22T13:40:25.874555Z",
     "shell.execute_reply": "2021-11-22T13:40:25.874333Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.874306Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
    "#     print(\"=> Saving checkpoint\")\n",
    "#     torch.save(state, filename)\n",
    "\n",
    "# def load_checkpoint(checkpoint, model):\n",
    "#     print(\"=> Loading checkpoint\")\n",
    "#     model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "\n",
    "# def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "#     loop = tqdm(loader)\n",
    "\n",
    "#     for batch_idx, (data, targets) in enumerate(loop):\n",
    "#         data = data.to(device=DEVICE)\n",
    "#         targets = targets.float().unsqueeze(1).to(device=DEVICE)\n",
    "\n",
    "#         # forward\n",
    "#         with torch.cuda.amp.autocast():\n",
    "#             predictions = model(data)\n",
    "#             loss = loss_fn(predictions, targets)\n",
    "\n",
    "#         # backward\n",
    "#         optimizer.zero_grad()\n",
    "#         scaler.scale(loss).backward()\n",
    "#         scaler.step(optimizer)\n",
    "#         scaler.update()\n",
    "\n",
    "#         # update tqdm loop\n",
    "#         loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "        \n",
    "# # model = UNET(in_channels=3, out_channels=1).to(config.DEVICE)\n",
    "# # loss_fn = nn.BCEWithLogitsLoss()\n",
    "# loss_fn = MixedLoss(10.0, 2.0)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "# # train_loader, val_loader = get_loaders(\n",
    "# #     TRAIN_IMG_DIR,\n",
    "# #     TRAIN_MASK_DIR,\n",
    "# #     VAL_IMG_DIR,\n",
    "# #     VAL_MASK_DIR,\n",
    "# #     BATCH_SIZE,\n",
    "# #     train_transform,\n",
    "# #     val_transforms,\n",
    "# #     NUM_WORKERS,\n",
    "# #     PIN_MEMORY,\n",
    "# # )\n",
    "\n",
    "# # if LOAD_MODEL:\n",
    "# #     load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model)\n",
    "\n",
    "\n",
    "# # check_accuracy(val_loader, model, device=DEVICE)\n",
    "# scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "#     train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
    "\n",
    "#     # save model\n",
    "#     checkpoint = {\n",
    "#         \"state_dict\": model.state_dict(),\n",
    "#         \"optimizer\":optimizer.state_dict(),\n",
    "#     }\n",
    "#     save_checkpoint(checkpoint)\n",
    "\n",
    "#     # check accuracy\n",
    "#     check_accuracy(val_loader, model, device=DEVICE)\n",
    "\n",
    "#     # print some examples to a folder\n",
    "#     save_predictions_as_imgs(\n",
    "#         val_loader, model, folder=\"saved_images/\", device=DEVICE\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137b7f9a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.875736Z",
     "iopub.status.idle": "2021-11-22T13:40:25.876335Z",
     "shell.execute_reply": "2021-11-22T13:40:25.876097Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.876069Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # from torch.multiprocessing import Pool, Process, set_start_method\n",
    "# # try:\n",
    "# #      set_start_method('spawn', force=True)\n",
    "# # # except RuntimeError:\n",
    "# #     pass\n",
    "\n",
    "# torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "# n_batches = len(train_dataloader)\n",
    "# # torch.multiprocessing.set_start_method('spawn')\n",
    "# model.to(device=DEVICE)\n",
    "# model.train()\n",
    "\n",
    "# criterion = MixedLoss(10.0, 2.0)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# for epoch in range(1, EPOCHS + 1):\n",
    "#     print(f\"Starting epoch: {epoch} / {EPOCHS}\")\n",
    "#     running_loss = 0.0\n",
    "#     optimizer.zero_grad()\n",
    "    \n",
    "#     for batch_idx, batch in enumerate(train_dataloader):\n",
    "        \n",
    "#         # Predict\n",
    "#         images, masks = batch\n",
    "#         images, masks = images.cuda(),  masks.cuda()\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, masks)\n",
    "        \n",
    "#         # Back prop\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#     epoch_loss = running_loss / n_batches\n",
    "#     print(f\"Epoch: {epoch} - Train Loss {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727d18ec",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.877517Z",
     "iopub.status.idle": "2021-11-22T13:40:25.878186Z",
     "shell.execute_reply": "2021-11-22T13:40:25.877916Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.877887Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FILE = \"./model0_50.pth\"\n",
    "# torch.save(model.state_dict(), FILE)\n",
    "\n",
    "# wandb.save(\"./model0_50.pth\")\n",
    "# # print(model.state_dict())\n",
    "# # loaded_model = Model(n_input_features=6)\n",
    "# # loaded_model.load_state_dict(torch.load(FILE)) # it takes the loaded dictionary, not the path file itself\n",
    "# # loaded_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461fb21e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c793b6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.879339Z",
     "iopub.status.idle": "2021-11-22T13:40:25.879924Z",
     "shell.execute_reply": "2021-11-22T13:40:25.879708Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.879680Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "# n_batches = len(dl_train)\n",
    "\n",
    "# model1.cuda()\n",
    "# model1.train()\n",
    "\n",
    "# criterion = MixedLoss(10.0, 2.0)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# for epoch in range(1, EPOCHS + 1):\n",
    "#     print(f\"Starting epoch: {epoch} / {EPOCHS}\")\n",
    "#     running_loss = 0.0\n",
    "#     optimizer.zero_grad()\n",
    "    \n",
    "#     for batch_idx, batch in enumerate(dl_train):\n",
    "        \n",
    "        \n",
    "#         images, masks = batch\n",
    "#         images, masks = images.cuda(),  masks.cuda()\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, masks)\n",
    "        \n",
    "        \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#     epoch_loss = running_loss / n_batches\n",
    "#     print(f\"Epoch: {epoch} - Train Loss {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d79bf1a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.881029Z",
     "iopub.status.idle": "2021-11-22T13:40:25.881634Z",
     "shell.execute_reply": "2021-11-22T13:40:25.881392Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.881365Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FILE1 = \"./model1_50.pth\"\n",
    "# torch.save(model1.state_dict(), FILE1)\n",
    "\n",
    "# wandb.save(\"./model1_50.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575fb2ec",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded19762",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.882789Z",
     "iopub.status.idle": "2021-11-22T13:40:25.883380Z",
     "shell.execute_reply": "2021-11-22T13:40:25.883144Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.883116Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "# n_batches = len(dl_train)\n",
    "\n",
    "# model2.cuda()\n",
    "# model3.train()\n",
    "\n",
    "# criterion = MixedLoss(10.0, 2.0)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# for epoch in range(1, EPOCHS + 1):\n",
    "#     print(f\"Starting epoch: {epoch} / {EPOCHS}\")\n",
    "#     running_loss = 0.0\n",
    "#     optimizer.zero_grad()\n",
    "    \n",
    "#     for batch_idx, batch in enumerate(dl_train):\n",
    "        \n",
    "        \n",
    "#         images, masks = batch\n",
    "#         images, masks = images.cuda(),  masks.cuda()\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, masks)\n",
    "        \n",
    "        \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#     epoch_loss = running_loss / n_batches\n",
    "#     print(f\"Epoch: {epoch} - Train Loss {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c51a068",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.884519Z",
     "iopub.status.idle": "2021-11-22T13:40:25.885117Z",
     "shell.execute_reply": "2021-11-22T13:40:25.884897Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.884870Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FILE2 = \"./model2_50.pth\"\n",
    "# torch.save(model2.state_dict(), FILE2)\n",
    "\n",
    "# wandb.save(\"./model2_50.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c808483d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2899862a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.886290Z",
     "iopub.status.idle": "2021-11-22T13:40:25.886990Z",
     "shell.execute_reply": "2021-11-22T13:40:25.886692Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.886663Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "# n_batches = len(dl_train)\n",
    "\n",
    "# model3.cuda()\n",
    "# model3.train()\n",
    "\n",
    "# criterion = MixedLoss(10.0, 2.0)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# for epoch in range(1, EPOCHS + 1):\n",
    "#     print(f\"Starting epoch: {epoch} / {EPOCHS}\")\n",
    "#     running_loss = 0.0\n",
    "#     optimizer.zero_grad()\n",
    "    \n",
    "#     for batch_idx, batch in enumerate(dl_train):\n",
    "        \n",
    "#         # Predict\n",
    "#         images, masks = batch\n",
    "#         images, masks = images.cuda(),  masks.cuda()\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, masks)\n",
    "        \n",
    "#         # Back prop\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#     epoch_loss = running_loss / n_batches\n",
    "#     print(f\"Epoch: {epoch} - Train Loss {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f32bba",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.888381Z",
     "iopub.status.idle": "2021-11-22T13:40:25.888977Z",
     "shell.execute_reply": "2021-11-22T13:40:25.888759Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.888731Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FILE3 = \"./model3_50.pth\"\n",
    "# torch.save(model3.state_dict(), FILE3)\n",
    "\n",
    "# wandb.save(\"./model3_50.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456b99f3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f67fda",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.890278Z",
     "iopub.status.idle": "2021-11-22T13:40:25.890896Z",
     "shell.execute_reply": "2021-11-22T13:40:25.890669Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.890641Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestCellDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.test_path = TEST_PATH\n",
    "        \n",
    "        \n",
    "        self.image_ids = [f[:-4]for f in os.listdir(self.test_path)]\n",
    "        self.num_samples = len(self.image_ids)\n",
    "        self.transform = Compose([Resize(IMAGE_RESIZE[0], IMAGE_RESIZE[1]), Normalize(mean=RESNET_MEAN, std=RESNET_STD, p=1), ToTensorV2()])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        path = os.path.join(self.test_path, image_id + \".png\")\n",
    "        image = cv2.imread(path)\n",
    "        image = self.transform(image=image)['image']\n",
    "        return {'image': image, 'id': image_id}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3cf4f1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.892023Z",
     "iopub.status.idle": "2021-11-22T13:40:25.892631Z",
     "shell.execute_reply": "2021-11-22T13:40:25.892392Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.892364Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del dl_train, ds_train, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb39b7d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.893938Z",
     "iopub.status.idle": "2021-11-22T13:40:25.894526Z",
     "shell.execute_reply": "2021-11-22T13:40:25.894310Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.894283Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_test = TestCellDataset()\n",
    "dl_test = DataLoader(ds_test, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bfc0f6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe1128",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.895641Z",
     "iopub.status.idle": "2021-11-22T13:40:25.896202Z",
     "shell.execute_reply": "2021-11-22T13:40:25.895976Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.895949Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def post_process(probability, threshold=0.5, min_size=300):\n",
    "    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n",
    "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    predictions = []\n",
    "    for c in range(1, num_component):\n",
    "        p = (component == c)\n",
    "        if p.sum() > min_size:\n",
    "            a_prediction = np.zeros((520, 704), np.float32)\n",
    "            a_prediction[p] = 1\n",
    "            predictions.append(a_prediction)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return ' '.join(map(str, run_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef04744",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.897258Z",
     "iopub.status.idle": "2021-11-22T13:40:25.897813Z",
     "shell.execute_reply": "2021-11-22T13:40:25.897605Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.897578Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.read_csv(SAMPLE_SUBMISSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685fae30",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.898882Z",
     "iopub.status.idle": "2021-11-22T13:40:25.899428Z",
     "shell.execute_reply": "2021-11-22T13:40:25.899223Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.899198Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_is_run_length(mask_rle):\n",
    "    if not mask_rle:\n",
    "        return True\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    start_prev = starts[0]\n",
    "    ok = True\n",
    "    for start in starts[1:]:\n",
    "        ok = ok and start > start_prev\n",
    "        start_prev = start\n",
    "        if not ok:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def create_empty_submission():\n",
    "    fs = os.listdir(\"../input/sartorius-cell-instance-segmentation/test\")\n",
    "    df = pd.DataFrame([(f[:-4], \"\") for f in fs], columns=['id', 'predicted'])\n",
    "    df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc53e901",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.900518Z",
     "iopub.status.idle": "2021-11-22T13:40:25.901079Z",
     "shell.execute_reply": "2021-11-22T13:40:25.900871Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.900843Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "submission = []\n",
    "for i, batch in enumerate(tqdm(dl_test)):\n",
    "    preds = torch.sigmoid(model(batch['image'].cuda()))\n",
    "    preds = preds.detach().cpu().numpy()[:, 0, :, :] # (batch_size, 1, size, size) -> (batch_size, size, size)\n",
    "    for image_id, probability_mask in zip(batch['id'], preds):\n",
    "        try:\n",
    "            #if probability_mask.shape != IMAGE_RESIZE:\n",
    "            #    probability_mask = cv2.resize(probability_mask, dsize=IMAGE_RESIZE, interpolation=cv2.INTER_LINEAR)\n",
    "            probability_mask = cv2.resize(probability_mask, dsize=(704, 520), interpolation=cv2.INTER_LINEAR)\n",
    "            predictions = post_process(probability_mask)\n",
    "            for prediction in predictions:\n",
    "                #plt.imshow(prediction)\n",
    "                #plt.show()\n",
    "                try:\n",
    "                    submission.append((image_id, rle_encoding(prediction)))\n",
    "                except:\n",
    "                    print(\"Error in RL encoding\")\n",
    "        except Exception as e:\n",
    "            print(f\"Exception for img: {image_id}: {e}\")\n",
    "        \n",
    "        # Fill images with no predictions\n",
    "        image_ids = [image_id for image_id, preds in submission]\n",
    "        if image_id not in image_ids:\n",
    "            submission.append((image_id, \"\"))\n",
    "            \n",
    "df_submission = pd.DataFrame(submission, columns=['id', 'predicted'])\n",
    "df_submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "if df_submission['predicted'].apply(check_is_run_length).mean() != 1:\n",
    "    print(\"Check run lenght failed\")\n",
    "    create_empty_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8ead0c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-22T13:40:25.902148Z",
     "iopub.status.idle": "2021-11-22T13:40:25.902722Z",
     "shell.execute_reply": "2021-11-22T13:40:25.902498Z",
     "shell.execute_reply.started": "2021-11-22T13:40:25.902472Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -r ./wandb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 71.725249,
   "end_time": "2021-11-22T14:08:19.991452",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-22T14:07:08.266203",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
