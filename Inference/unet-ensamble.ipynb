{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q ../input/segmentation-models-wheels/efficientnet_pytorch-0.6.3-py3-none-any.whl \n!pip install -q ../input/segmentation-models-wheels/pretrainedmodels-0.7.4-py3-none-any.whl\n!pip install -q ../input/segmentation-models-wheels/timm-0.3.2-py3-none-any.whl\n!pip install -q ../input/segmentation-models-wheels/segmentation_models_pytorch-0.1.3-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2021-11-22T19:32:57.242999Z","iopub.execute_input":"2021-11-22T19:32:57.244125Z","iopub.status.idle":"2021-11-22T19:33:26.848945Z","shell.execute_reply.started":"2021-11-22T19:32:57.244085Z","shell.execute_reply":"2021-11-22T19:33:26.848136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nimport os\nimport cv2\nimport time\nimport warnings\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm_notebook as tqdm\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.model_selection import KFold\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, Dataset, sampler\nfrom matplotlib import pyplot as plt\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score, f1_score\nimport torch\nimport collections.abc as container_abcs\ntorch._six.container_abcs = container_abcs\nimport segmentation_models_pytorch as smp\nwarnings.filterwarnings(\"ignore\")\n\n\ndef fix_all_seeds(seed):\n    np.random.seed(seed)\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    \nfix_all_seeds(2021)\n\n# from wandb.keras import WandbCallback","metadata":{"execution":{"iopub.status.busy":"2021-11-22T19:33:26.852293Z","iopub.execute_input":"2021-11-22T19:33:26.852538Z","iopub.status.idle":"2021-11-22T19:33:32.402001Z","shell.execute_reply.started":"2021-11-22T19:33:26.85251Z","shell.execute_reply":"2021-11-22T19:33:32.401222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"WANDB\")\n    wandb.login(key=api_key)\n    anonymous = None\nexcept:\n    anonymous = \"must\"\n    print('To use your W&B account,\\nGo to Add-ons -> Secrets and provide your W&B access token. Use the Label name as WANDB. \\nGet your W&B access token from here: https://wandb.ai/authorize')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-22T19:33:32.404194Z","iopub.execute_input":"2021-11-22T19:33:32.40441Z","iopub.status.idle":"2021-11-22T19:33:33.621307Z","shell.execute_reply.started":"2021-11-22T19:33:32.404384Z","shell.execute_reply":"2021-11-22T19:33:33.620627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:\n    seed          = 101\n    debug         = False # set debug=False for Full Training\n    exp_name      = 'Unet-effnetb2-512x512-aug2'\n    model_name    = 'Unet'\n    backbone0     = 'efficientnet-b2'\n    backbone1     = 'efficientnet-b7'\n    backbone2     = 'efficientnet-b6'\n    backbone3     = 'efficientnet-b5'\n    batch_size    = 8\n    train_bs      = 24\n    valid_bs      = 48\n    IMAGE_RESIZE  = (512, 512)\n    epochs        = 2\n    lr            = 5e-3\n    scheduler     = 'CosineAnnealingLR'\n    min_lr        = 1e-6\n    T_max         = int(100*6*1.8)\n    T_0           = 25\n    warmup_epochs = 0\n    wd            = 1e-6\n    n_accumulate  = 32//train_bs\n#     n_fold        = 5\n    num_classes   = 1\n    DEVICE        = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    competition   = 'sartorius'\n    _wandb_kernel = 'somusan'\n    TEST_PATH     = \"../input/sartorius-cell-instance-segmentation/test\"","metadata":{"execution":{"iopub.status.busy":"2021-11-22T19:33:33.622505Z","iopub.execute_input":"2021-11-22T19:33:33.622771Z","iopub.status.idle":"2021-11-22T19:33:33.672182Z","shell.execute_reply.started":"2021-11-22T19:33:33.622735Z","shell.execute_reply":"2021-11-22T19:33:33.671512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = smp.Unet(config.backbone0, encoder_weights=\"imagenet\", classes=1,activation=None)\nmodel1 = smp.Unet(config.backbone1, encoder_weights=\"imagenet\", classes=1,activation=None)\nmodel2 = smp.Unet(config.backbone2, encoder_weights=\"imagenet\", classes=1,activation=None)\nmodel3 = smp.Unet(config.backbone3, encoder_weights=\"imagenet\", classes=1,activation=None)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T19:33:33.674049Z","iopub.execute_input":"2021-11-22T19:33:33.674727Z","iopub.status.idle":"2021-11-22T19:33:49.324616Z","shell.execute_reply.started":"2021-11-22T19:33:33.674677Z","shell.execute_reply":"2021-11-22T19:33:49.323819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model0 = wandb.restore('model0.pth', run_path=\"somusan/kaggle_sartorius_unet_ensemble/dnhtjlrc\")\nmodel.load_state_dict(torch.load(best_model0.name))\n\nbest_model1 = wandb.restore('model1.pth', run_path=\"somusan/kaggle_sartorius_unet_ensemble/dnhtjlrc\")\nmodel1.load_state_dict(torch.load(best_model1.name))\n\nbest_model2 = wandb.restore('model2.pth', run_path=\"somusan/kaggle_sartorius_unet_ensemble/dnhtjlrc\")\nmodel2.load_state_dict(torch.load(best_model2.name))\n\nbest_model3 = wandb.restore('model3.pth', run_path=\"somusan/kaggle_sartorius_unet_ensemble/dnhtjlrc\")\nmodel3.load_state_dict(torch.load(best_model3.name))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T19:33:49.326194Z","iopub.execute_input":"2021-11-22T19:33:49.326705Z","iopub.status.idle":"2021-11-22T19:34:11.716999Z","shell.execute_reply.started":"2021-11-22T19:33:49.326656Z","shell.execute_reply":"2021-11-22T19:34:11.716217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestCellDataset(Dataset):\n    def __init__(self):\n        self.test_path = config.TEST_PATH\n        \n        \n        self.image_ids = [f[:-4]for f in os.listdir(self.test_path)]\n        self.num_samples = len(self.image_ids)\n        self.transform = A.Compose([A.Resize(config.IMAGE_RESIZE[0], config.IMAGE_RESIZE[1]), ToTensorV2()])\n\n    def __getitem__(self, idx):\n        image_id = self.image_ids[idx]\n        path = os.path.join(self.test_path, image_id + \".png\")\n        image = cv2.imread(path)\n        image = self.transform(image=image)['image']\n        return {'image': image, 'id': image_id}\n\n    def __len__(self):\n        return self.num_samples","metadata":{"execution":{"iopub.status.busy":"2021-11-22T19:34:11.718488Z","iopub.execute_input":"2021-11-22T19:34:11.718758Z","iopub.status.idle":"2021-11-22T19:34:11.728599Z","shell.execute_reply.started":"2021-11-22T19:34:11.718721Z","shell.execute_reply":"2021-11-22T19:34:11.727673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds_test = TestCellDataset()\ndl_test = DataLoader(ds_test, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T19:34:11.72991Z","iopub.execute_input":"2021-11-22T19:34:11.730269Z","iopub.status.idle":"2021-11-22T19:34:11.745752Z","shell.execute_reply.started":"2021-11-22T19:34:11.730228Z","shell.execute_reply":"2021-11-22T19:34:11.744926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def post_process(probability, threshold=0.5, min_size=300):\n    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n    predictions = []\n    for c in range(1, num_component):\n        p = (component == c)\n        if p.sum() > min_size:\n            a_prediction = np.zeros((520, 704), np.float32)\n            a_prediction[p] = 1\n            predictions.append(a_prediction)\n    return predictions\n\n\ndef rle_encoding(x):\n    dots = np.where(x.flatten() == 1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return ' '.join(map(str, run_lengths))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T19:34:11.748466Z","iopub.execute_input":"2021-11-22T19:34:11.74866Z","iopub.status.idle":"2021-11-22T19:34:11.756889Z","shell.execute_reply.started":"2021-11-22T19:34:11.748636Z","shell.execute_reply":"2021-11-22T19:34:11.755704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_preds(model):\n    model.eval()\n    submission = []\n    for i, batch in enumerate(tqdm(dl_test)):\n        preds = torch.sigmoid(model(batch['image'].float()))\n        preds = preds.detach().cpu().numpy()[:, 0, :, :] # (batch_size, 1, size, size) -> (batch_size, size, size)\n        for image_id, probability_mask in zip(batch['id'], preds):\n            probability_mask = cv2.resize(probability_mask, dsize=(704, 520), interpolation=cv2.INTER_LINEAR)\n            submission.append(probability_mask)\n    return submission","metadata":{"execution":{"iopub.status.busy":"2021-11-22T20:05:01.565555Z","iopub.execute_input":"2021-11-22T20:05:01.565845Z","iopub.status.idle":"2021-11-22T20:05:01.571801Z","shell.execute_reply.started":"2021-11-22T20:05:01.565815Z","shell.execute_reply":"2021-11-22T20:05:01.571097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(submission[0]>0.5)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T19:50:20.166324Z","iopub.execute_input":"2021-11-22T19:50:20.167344Z","iopub.status.idle":"2021-11-22T19:50:20.425864Z","shell.execute_reply.started":"2021-11-22T19:50:20.167304Z","shell.execute_reply":"2021-11-22T19:50:20.425217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport cv2 as cv\nfrom matplotlib import pyplot as plt\n# img = cv.imread('opencv_logo.png')\nplt.figure(figsize=(20,20))\nimg = submission[0] > 0.5\n# kernel = np.ones((5,5),np.float32)/25\n# dst = cv.filter2D(submission[0],-1,kernel)\ndst = cv2.medianBlur(img, 5)\nplt.subplot(121),plt.imshow(img),plt.title('Original')\nplt.xticks([]), plt.yticks([])\nplt.subplot(122),plt.imshow(dst),plt.title('Averaging')\nplt.xticks([]), plt.yticks([])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T20:01:42.486866Z","iopub.execute_input":"2021-11-22T20:01:42.487233Z","iopub.status.idle":"2021-11-22T20:01:42.527192Z","shell.execute_reply.started":"2021-11-22T20:01:42.487198Z","shell.execute_reply":"2021-11-22T20:01:42.525993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\nsubmission = []\nfor i, batch in enumerate(tqdm(dl_test)):\n    preds = torch.sigmoid(model(batch['image'].cuda()))\n    preds = preds.detach().cpu().numpy()[:, 0, :, :] # (batch_size, 1, size, size) -> (batch_size, size, size)\n    for image_id, probability_mask in zip(batch['id'], preds):\n        try:\n            #if probability_mask.shape != IMAGE_RESIZE:\n            #    probability_mask = cv2.resize(probability_mask, dsize=IMAGE_RESIZE, interpolation=cv2.INTER_LINEAR)\n            probability_mask = cv2.resize(probability_mask, dsize=(704, 520), interpolation=cv2.INTER_LINEAR)\n            predictions = post_process(probability_mask)\n            for prediction in predictions:\n                #plt.imshow(prediction)\n                #plt.show()\n                try:\n                    submission.append((image_id, rle_encoding(prediction)))\n                except:\n                    print(\"Error in RL encoding\")\n        except Exception as e:\n            print(f\"Exception for img: {image_id}: {e}\")\n        \n        # Fill images with no predictions\n        image_ids = [image_id for image_id, preds in submission]\n        if image_id not in image_ids:\n            submission.append((image_id, \"\"))\n            \ndf_submission = pd.DataFrame(submission, columns=['id', 'predicted'])\ndf_submission.to_csv('submission.csv', index=False)\n\nif df_submission['predicted'].apply(check_is_run_length).mean() != 1:\n    print(\"Check run lenght failed\")\n    create_empty_submission()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# from keras.models import load_model\n\n#Set compile=False as we are not loading it for training, only for prediction.\n# model1 = load_model('saved_models/res34_backbone_50epochs.hdf5', compile=False)\n# model2 = load_model('saved_models/inceptionv3_backbone_50epochs.hdf5', compile=False)\n# model3 = load_model('saved_models/vgg19_backbone_50epochs.hdf5', compile=False)\n\n#Weighted average ensemble\n# models = [model1, model2, model3]\n#preds = [model.predict(X_test) for model in models]\n\n# pred1 = model1.predict(X_test1)\n# pred2 = model2.predict(X_test2)\n# pred3 = model3.predict(X_test3)\n\npred0 = get_preds(model)\npred1 = get_preds(model1)\npred2 = get_preds(model2)\npred3 = get_preds(model3)\n\n\n\npreds=np.array([pred0[0], pred1[0], pred2[0], pred3[0]])\n\n#preds=np.array(preds)\nweights = [0.3, 0.5, 0.3,0.4]\n\n#Use tensordot to sum the products of all elements over specified axes.\nweighted_preds = np.tensordot(preds, weights, axes=((0),(0)))\nweighted_ensemble_prediction = np.argmax(weighted_preds, axis=3)\n\ny_pred1_argmax=np.argmax(pred1, axis=3)\ny_pred2_argmax=np.argmax(pred2, axis=3)\ny_pred3_argmax=np.argmax(pred3, axis=3)\n\n\n#Using built in keras function\nn_classes = 1\nIOU1 = MeanIoU(num_classes=n_classes)  \nIOU2 = MeanIoU(num_classes=n_classes)  \nIOU3 = MeanIoU(num_classes=n_classes)  \nIOU_weighted = MeanIoU(num_classes=n_classes)  \n\nIOU1.update_state(y_test[:,:,:,0], y_pred1_argmax)\nIOU2.update_state(y_test[:,:,:,0], y_pred2_argmax)\nIOU3.update_state(y_test[:,:,:,0], y_pred3_argmax)\nIOU_weighted.update_state(y_test[:,:,:,0], weighted_ensemble_prediction)\n\n\nprint('IOU Score for model1 = ', IOU1.result().numpy())\nprint('IOU Score for model2 = ', IOU2.result().numpy())\nprint('IOU Score for model3 = ', IOU3.result().numpy())\nprint('IOU Score for weighted average ensemble = ', IOU_weighted.result().numpy())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}